{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62baf72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "n_example = 5000 #生成数据的个数\n",
    "n_train = 4500\n",
    "n_test = 500\n",
    "\n",
    "n_dim = 2 # 输入数据的维数\n",
    "#即显模式\n",
    "tf.compat.v1.enable_eager_execution()# 动态图机制\n",
    "#tf.compat.v1.disable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04967293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成训练集和测试集 输入数据x,y\n",
    "# 训练集输入数据 产生特征，以均匀分布随机生成 数据点(𝑥, 𝑦)\n",
    "train_X = tf.random.uniform((n_train, n_dim), -10,10)\n",
    "\n",
    "# 测试集输入数据\n",
    "test_X = tf.random.uniform((n_test, n_dim), -10,10)\n",
    "\n",
    "# 设置真实的 weight, bias\n",
    "w_real = [1, 1 ,1]\n",
    "b_real = 0\n",
    "#生成标准输出数据\n",
    "labels_train = w_real[0] * train_X[:,0] *  train_X[:,0] + w_real[1] * train_X[:,1]* train_X[:,1]  + w_real[2] * train_X[:,1] * train_X[:,0] + b_real \n",
    "labels_test = w_real[0] * test_X[:,0] *  test_X[:,0] + w_real[1] * test_X[:,1]* test_X[:,1]  + w_real[2] * test_X[:,1] * test_X[:,0] + b_real \n",
    "\n",
    "# 为标准输出数据添加噪声得到训练与测试输出数据\n",
    "train_z = labels_train + tf.random.normal(labels_train.shape, stddev=0.01)\n",
    "test_z = labels_test + tf.random.normal(labels_test.shape, stddev=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aea319cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02763dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e0a79c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型类\n",
    "class Model():\n",
    "    def __init__(self):\n",
    "        # 初始化模型参数\n",
    "        self.w = tf.Variable(tf.random.normal([n_dim, 10], mean=1.0 , stddev=0.1))\n",
    "        self.b = tf.Variable(tf.zeros(1,))\n",
    "        \n",
    "        self.w1 = tf.Variable(tf.random.normal([10, 1], mean=1.0 , stddev=0.1))\n",
    "        self.b1 = tf.Variable(tf.zeros(1,))\n",
    "        \n",
    "#         self.w2 = tf.Variable(tf.random.normal([3, 1], mean=1.0 , stddev=0.1))\n",
    "#         self.b2 = tf.Variable(tf.zeros(1,))\n",
    "        # 变量通过 tf.Variable 类进行创建和跟踪。tf.Variable 表示张量，对它执行运算可以改变其值。利用特定运算可以读取和修改此张量的值。\n",
    "        # 更高级的库（如 tf.keras）使用 tf.Variable 来存储模型参数。\n",
    "    def __call__(self,X):#该方法的功能类似于在类中重载 () 运算符，使得类实例对象可以像调用普通函数那样，以“对象名()”的形式使用。\n",
    "        # 正向传递\n",
    "        # 第一层\n",
    "        H1 = tf.nn.relu(tf.matmul(X, self.w) + self.b)\n",
    "#         # 第二层\n",
    "#         H2 = tf.nn.relu(tf.matmul(H1, self.w1) + self.b1)\n",
    "        # 第三层\n",
    "        z = tf.nn.relu(tf.matmul(H1, self.w1) + self.b1)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d79426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化模型\n",
    "model = Model()\n",
    "# saver = tf.compat.v1.train.Saver()\n",
    "# sess = tf.compat.v1.Session()\n",
    "# sess.run(tf.compat.v1.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7dd25a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数MSE\n",
    "# 通常情况下取回归模型的 Loss 函数为 MSE\n",
    "def squared_loss(y, y_hat, n):\n",
    "  y_observed = tf.reshape(y, y_hat.shape)\n",
    "  return tf.matmul(tf.transpose(y_observed - y_hat), \n",
    "                   y_observed - y_hat) / 2 / n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fce2fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置数据迭代函数\n",
    "def data_iter(features, labels, mini_batch):\n",
    "#   Args:\n",
    "#   - features: 特征矩阵 nxd 维\n",
    "#   - labels: 样本，nx1 维\n",
    "#   - mini_batch: 每次抽取的样本数\n",
    "  features = np.array(features)\n",
    "  labels = np.array(labels)\n",
    "  indeces = list(range(len(features)))\n",
    "  random.shuffle(indeces)\n",
    "  for i in range(0, len(indeces), mini_batch):\n",
    "    j = np.array(indeces[i:min(i+mini_batch, len(features))])\n",
    "    yield features[j], labels[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27c07b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算梯度，并更新模型参数\n",
    "def sgd(params, lr):\n",
    "#   Args:\n",
    "#   params: 模型参数\n",
    "#   lr: 学习率 learning rate\n",
    "  for param in params:\n",
    "    param.assign_sub(lr * t.gradient(l, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5804b402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置学习率，迭代次数,batch大小\n",
    "learning_rate = 0.001\n",
    "epoch = 40\n",
    "batch = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dfb7622",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjyjy2001lfx\u001b[0m (\u001b[33mjnjy\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>F:\\jupyterNotebook\\cvExperiment\\wandb\\run-20230327_164056-houg3361</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jnjy/ex1/runs/houg3361' target=\"_blank\">0327164053</a></strong> to <a href='https://wandb.ai/jnjy/ex1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jnjy/ex1' target=\"_blank\">https://wandb.ai/jnjy/ex1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jnjy/ex1/runs/houg3361' target=\"_blank\">https://wandb.ai/jnjy/ex1/runs/houg3361</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/jnjy/ex1/runs/houg3361?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x22d0421ee00>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb #数据可视化\n",
    "import time\n",
    "wandb.init(project='ex1', name=time.strftime('%m%d%H%M%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb7623b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train_loss 118.958725\n",
      "epoch 1, test_loss 110.895454\n",
      "epoch 2, train_loss 80.526779\n",
      "epoch 2, test_loss 77.380219\n",
      "epoch 3, train_loss 66.999260\n",
      "epoch 3, test_loss 66.838142\n",
      "epoch 4, train_loss 56.878422\n",
      "epoch 4, test_loss 55.487015\n",
      "epoch 5, train_loss 52.925468\n",
      "epoch 5, test_loss 52.357197\n",
      "epoch 6, train_loss 49.040100\n",
      "epoch 6, test_loss 46.843433\n",
      "epoch 7, train_loss 46.353794\n",
      "epoch 7, test_loss 42.455090\n",
      "epoch 8, train_loss 44.966373\n",
      "epoch 8, test_loss 42.781700\n",
      "epoch 9, train_loss 43.740887\n",
      "epoch 9, test_loss 40.272388\n",
      "epoch 10, train_loss 42.445038\n",
      "epoch 10, test_loss 39.917042\n",
      "epoch 11, train_loss 41.118366\n",
      "epoch 11, test_loss 36.622387\n",
      "epoch 12, train_loss 39.459991\n",
      "epoch 12, test_loss 35.984268\n",
      "epoch 13, train_loss 38.640076\n",
      "epoch 13, test_loss 37.154236\n",
      "epoch 14, train_loss 36.348103\n",
      "epoch 14, test_loss 33.151711\n",
      "epoch 15, train_loss 35.002457\n",
      "epoch 15, test_loss 32.614517\n",
      "epoch 16, train_loss 33.957405\n",
      "epoch 16, test_loss 31.780867\n",
      "epoch 17, train_loss 33.252586\n",
      "epoch 17, test_loss 31.644695\n",
      "epoch 18, train_loss 32.492245\n",
      "epoch 18, test_loss 29.801262\n",
      "epoch 19, train_loss 31.886646\n",
      "epoch 19, test_loss 29.603849\n",
      "epoch 20, train_loss 31.703541\n",
      "epoch 20, test_loss 28.522488\n",
      "epoch 21, train_loss 30.915874\n",
      "epoch 21, test_loss 28.743038\n",
      "epoch 22, train_loss 30.707174\n",
      "epoch 22, test_loss 27.867172\n",
      "epoch 23, train_loss 30.499826\n",
      "epoch 23, test_loss 28.887960\n",
      "epoch 24, train_loss 29.995298\n",
      "epoch 24, test_loss 27.721870\n",
      "epoch 25, train_loss 30.738544\n",
      "epoch 25, test_loss 29.884651\n",
      "epoch 26, train_loss 29.818815\n",
      "epoch 26, test_loss 26.669825\n",
      "epoch 27, train_loss 29.306690\n",
      "epoch 27, test_loss 26.679573\n",
      "epoch 28, train_loss 29.445257\n",
      "epoch 28, test_loss 26.119431\n",
      "epoch 29, train_loss 28.900013\n",
      "epoch 29, test_loss 26.303675\n",
      "epoch 30, train_loss 29.742188\n",
      "epoch 30, test_loss 25.713350\n",
      "epoch 31, train_loss 28.371923\n",
      "epoch 31, test_loss 25.793386\n",
      "epoch 32, train_loss 28.001532\n",
      "epoch 32, test_loss 25.711506\n",
      "epoch 33, train_loss 27.501390\n",
      "epoch 33, test_loss 25.332554\n",
      "epoch 34, train_loss 26.918163\n",
      "epoch 34, test_loss 24.399628\n",
      "epoch 35, train_loss 26.177574\n",
      "epoch 35, test_loss 24.290359\n",
      "epoch 36, train_loss 26.111523\n",
      "epoch 36, test_loss 25.318464\n",
      "epoch 37, train_loss 25.445744\n",
      "epoch 37, test_loss 23.654591\n",
      "epoch 38, train_loss 24.926601\n",
      "epoch 38, test_loss 23.589266\n",
      "epoch 39, train_loss 24.426561\n",
      "epoch 39, test_loss 23.025845\n",
      "epoch 40, train_loss 23.860632\n",
      "epoch 40, test_loss 22.602594\n",
      "Final Test loss 22.602594\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# 开始训练\n",
    "for i in range(epoch):\n",
    "    for X, y in data_iter(train_X, train_z, batch):\n",
    "            # 在内存中记录梯度过程\n",
    "        with tf.GradientTape(persistent=True) as t:\n",
    "            t.watch([model.w, model.b,model.w1, model.b1])\n",
    "            # 计算本次小批量的 loss\n",
    "            l = squared_loss(y, model(X), batch)\n",
    "        # 计算梯度，更新参数\n",
    "        sgd([model.w, model.b], learning_rate)\n",
    "    # 计算本次迭代的总误差\n",
    "\n",
    "    train_loss = squared_loss(train_z, model(train_X), len(train_X))\n",
    "    wandb.log({'epoch': i, 'train_loss': tf.reduce_mean(train_loss)})\n",
    "    print('epoch %d, train_loss %f' % (i + 1, tf.reduce_mean(train_loss)))\n",
    "    test_loss = squared_loss(test_z, model(test_X), len(test_X))\n",
    "    wandb.log({'epoch': i, 'test_loss': tf.reduce_mean(test_loss)})\n",
    "    print('epoch %d, test_loss %f' % (i + 1, tf.reduce_mean(test_loss)))\n",
    "\n",
    "test_loss = squared_loss(test_z, model(test_X), len(test_X))\n",
    "print('Final Test loss %f' % (tf.reduce_mean(test_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab7205eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 10) dtype=float32, numpy=\n",
       "array([[ 0.6095568 , -9.03813   ,  1.418492  ,  2.7814357 ,  1.717465  ,\n",
       "        -3.0528345 ,  1.3593342 ,  1.3406638 ,  5.352766  ,  7.724582  ],\n",
       "       [ 2.3965478 , -3.411656  ,  8.182209  ,  0.5449532 ,  1.3374546 ,\n",
       "        -9.155383  ,  1.6765924 ,  3.5384512 ,  3.2178736 ,  0.73620814]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a677c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "# tf.keras.models.save_model(model,'./CV_ex1_model_save/one_hide_layer')\n",
    "# tf.saved_model.save(model,'./CV_ex1_model_save/one_hide_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5452d2f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
