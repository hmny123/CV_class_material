{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c23be73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "# 获取可用的 GPU 设备列表\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f739467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "lr = 0.001\n",
    "batch_size = 256\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "234c32bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 16:44:42.712822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-11 16:44:42.722701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-11 16:44:42.723012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-11 16:44:42.724120: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-11 16:44:42.724802: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-11 16:44:42.725067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-11 16:44:42.725204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-11 16:44:43.650354: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-11 16:44:43.650671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-11 16:44:43.650833: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-11 16:44:43.651041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8098 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:10:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# 定义卷积神经网络模型\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu', input_shape=(32, 32, 3)), # 输入通道数为3，输出通道数为64，卷积核大小为3x3，填充为1\n",
    "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu',kernel_regularizer=regularizers.l2(0.001)), # 输入通道数为64，输出通道数为64，卷积核大小为3x3，填充为1\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2), # 最大池化层，大小为2x2，步幅为2\n",
    "    tf.keras.layers.Dropout(0.05),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'), # 输入通道数为64，输出通道数为128，卷积核大小为3x3，填充为1\n",
    "    tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.001)), # 输入通道数为128，输出通道数为128，卷积核大小为3x3，填充为1\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    # 设置 kernel_regularizer 参数来实现 L2 正则化。其中 0.001 是 L2 正则化系数。\n",
    "    tf.keras.layers.MaxPooling2D(2, 2), # 最大池化层，大小为2x2，步幅为2\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu'), # 输入通道数为128，输出通道数为256，卷积核大小为3x3，填充为1\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu'), \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.001)), # 输入通道数为256，输出通道数为256，卷积核大小为3x3，填充为1\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2), # 最大池化层，大小为2x2，步幅为2\n",
    "    tf.keras.layers.Dropout(0.15),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2), \n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2), \n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    tf.keras.layers.Flatten(), # 将张量展开为一维张量\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1024, activation='relu'), # 全连接层1，输入维度为256*4*4，输出维度为1024\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(512, activation='relu',kernel_regularizer=regularizers.l2(0.001)), # 全连接层2，输入维度为1024，输出维度为512\n",
    "    tf.keras.layers.Dense(10, activation='softmax') # 输出层，输入维度为512，输出维度为10\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0546476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练集和测试集的数据增强\n",
    "train_transform = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomTranslation(0.1, 0.1),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "    tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
    "])\n",
    "\n",
    "test_transform = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86381e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 16:44:48.106845: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/40 [========>.....................] - ETA: 0s - loss: 0.4821 - accuracy: 0.8896"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 16:44:51.006335: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 5s 18ms/step - loss: 0.4724 - accuracy: 0.8898\n",
      "Test accuracy: 0.8898000121116638\n"
     ]
    }
   ],
   "source": [
    "# 读取模型\n",
    "model = load_model('my_model_final_best.h5')\n",
    "\n",
    "# 加载 CIFAR-10 数据集\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# 将标签转换为 one-hot 编码\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.map(lambda x, y: (test_transform(x), y))\n",
    "test_dataset = test_dataset.batch(batch_size=batch_size)\n",
    "test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "#  让数据集对象 Dataset 在训练时预取出若干个元素，使得在 GPU 训练的同时 CPU 可以准备数据，从而提升训练流程的效率\n",
    "\n",
    "# 进行测试\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "546abc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conv2d', 'conv2d_1', 'batch_normalization', 'max_pooling2d', 'dropout', 'conv2d_2', 'conv2d_3', 'batch_normalization_1', 'max_pooling2d_1', 'dropout_1', 'conv2d_4', 'batch_normalization_2', 'conv2d_5', 'batch_normalization_3', 'conv2d_6', 'batch_normalization_4', 'max_pooling2d_2', 'dropout_2', 'conv2d_7', 'batch_normalization_5', 'conv2d_8', 'batch_normalization_6', 'conv2d_9', 'batch_normalization_7', 'max_pooling2d_3', 'dropout_3', 'conv2d_10', 'batch_normalization_8', 'conv2d_11', 'batch_normalization_9', 'conv2d_12', 'batch_normalization_10', 'max_pooling2d_4', 'dropout_4', 'flatten', 'dropout_5', 'dense', 'dropout_6', 'dense_1', 'dropout_7', 'dense_2', 'dense_3'] 42\n"
     ]
    }
   ],
   "source": [
    "# 打印神经网络各层名称\n",
    "names = [layer.name for layer in model.layers]\n",
    "print(names, len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7d6dd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #打印神经网络结构\n",
    "# for layer in model.layers:\n",
    "#         for weight in layer.weights:\n",
    "#             print(weight.name, weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "83e377e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_12\n",
      "conv2d_12/kernel:0 (3, 3, 512, 512)\n",
      "conv2d_12/bias:0 (512,)\n",
      "conv2d_12\n",
      "conv2d_12/kernel:0 (3, 3, 512, 512)\n",
      "conv2d_12/bias:0 (512,)\n",
      "conv2d_9\n",
      "conv2d_9/kernel:0 (3, 3, 512, 512)\n",
      "conv2d_9/bias:0 (512,)\n"
     ]
    }
   ],
   "source": [
    "# 打印寻找最后一个卷积层\n",
    "conv_layer = model.get_layer(name='conv2d_12')\n",
    "conv_layer\n",
    "print(conv_layer.name)\n",
    "for weight in conv_layer.weights:\n",
    "    print(weight.name, weight.shape)\n",
    "# conv2d_12/kernel:0 (3, 3, 512, 512) 卷积核大小3*3 输入通道数512 输出通道数512\n",
    "\n",
    "conv_layer = model.get_layer(index=-12)\n",
    "print(conv_layer.name)\n",
    "for weight in conv_layer.weights:\n",
    "    print(weight.name, weight.shape)\n",
    "    \n",
    "conv_layer = model.get_layer(index=-20)\n",
    "print(conv_layer.name)\n",
    "for weight in conv_layer.weights:\n",
    "    print(weight.name, weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e7c15f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 显示特征图 参考代码\n",
    "# def showFeatureMap(featureMap,k):\n",
    "#     if not os.path.exists(rootPath):\n",
    "#         os.mkdir(rootPath)\n",
    "#     kPath = os.path.join(rootPath,str(k))\n",
    "#     if not os.path.exists(kPath):\n",
    "#         os.mkdir(kPath)\n",
    "#     featureMap = featureMap. squeeze(0)\n",
    "#     featureMapNum = featureMap.shape[0] #返回通道数\n",
    "#     row_num = np.ceil(np.sqrt(featureMapNum))#将通道数开方取整，尽可能地使行列数相同\n",
    "#     plt.figure()\n",
    "#     for index in range(1,featureMapNum + 1):#通过遍历的方式，将每个特征图拿出\n",
    "#         plt.subplot(row_num,row_num,index)\n",
    "#         plt.imshow(featureMap[index - 1],cmap='gray')\n",
    "#         plt.axis('off')\n",
    "#         #保存特征图到指定的路径下\n",
    "#         scipy.misc.imsave(os.path.join(kPath,str(index) + '.png'),featureMap[index - 1])#将这一层所有的特征图合并显示并保存\n",
    "#     plt.savefig(os.path.join(kPath,'totImg.png' ))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "201ea51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 512), dtype=float32, numpy=\n",
       "array([[[0.35425472, 0.58658934, 0.16616865, ..., 0.3775052 ,\n",
       "         0.253711  , 0.2337245 ],\n",
       "        [0.18189467, 0.7158923 , 0.04594743, ..., 0.49970454,\n",
       "         0.44316137, 0.65379816]],\n",
       "\n",
       "       [[0.5165768 , 0.41051158, 0.18278298, ..., 0.20512286,\n",
       "         0.19628273, 0.5447516 ],\n",
       "        [0.13349736, 0.39791712, 0.3625206 , ..., 0.1542081 ,\n",
       "         0.47224835, 0.23300618]]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_conv_layer = model.layers[-12]\n",
    "last_conv_layer_model = tf.keras.models.Model(model.inputs, last_conv_layer.output)\n",
    "conv_outputs = last_conv_layer_model.predict(test_dataset)\n",
    "# conv_outputs\n",
    "average_output = tf.reduce_mean(conv_outputs, axis=0)\n",
    "average_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9529aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 512 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 打印最后一层卷积层（剪枝前） 在整个测试数据集上的平均输出特征图\n",
    "plt.imshow(average_output[:,:,0], cmap='gray') #打印第0张平均输出特征图\n",
    "plt.show()\n",
    "# plt.imshow(average_output[:,:,1], cmap='gray')\n",
    "# plt.show()\n",
    "row_num = int(np.ceil(np.sqrt(average_output.shape[2])))#将通道数开方取整，尽可能地使行列数相同\n",
    "row_num\n",
    "for index in range(1,average_output.shape[2]+1):#通过遍历的方式，将每个特征图拿出\n",
    "    plt.subplot(row_num,row_num,index)\n",
    "    plt.imshow(average_output[:,:,index-1],cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8479fd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuron 236: 0.03269832581281662\n",
      "Neuron 383: 0.05992547422647476\n",
      "Neuron 125: 0.07034046947956085\n",
      "Neuron 491: 0.08466646820306778\n",
      "Neuron 218: 0.08590062707662582\n",
      "Neuron 92: 0.08756137639284134\n",
      "Neuron 380: 0.10096488893032074\n",
      "Neuron 427: 0.10129434615373611\n",
      "Neuron 104: 0.10306920111179352\n",
      "Neuron 454: 0.10644809901714325\n",
      "Neuron 61: 0.10692503303289413\n",
      "Neuron 336: 0.11001578718423843\n",
      "Neuron 250: 0.11110815405845642\n",
      "Neuron 172: 0.11362634599208832\n",
      "Neuron 307: 0.11739332228899002\n",
      "Neuron 148: 0.12002052366733551\n",
      "Neuron 247: 0.12507620453834534\n",
      "Neuron 198: 0.12552356719970703\n",
      "Neuron 419: 0.12754957377910614\n",
      "Neuron 42: 0.1288086473941803\n",
      "Neuron 311: 0.12914273142814636\n",
      "Neuron 77: 0.1298746019601822\n",
      "Neuron 75: 0.13046099245548248\n",
      "Neuron 471: 0.1351509839296341\n",
      "Neuron 470: 0.13604474067687988\n",
      "Neuron 296: 0.1363120824098587\n",
      "Neuron 404: 0.1368200033903122\n",
      "Neuron 95: 0.1377684772014618\n",
      "Neuron 240: 0.13837897777557373\n",
      "Neuron 98: 0.1384437531232834\n",
      "Neuron 90: 0.1385039985179901\n",
      "Neuron 189: 0.1391487419605255\n",
      "Neuron 163: 0.13957670331001282\n",
      "Neuron 330: 0.13968823850154877\n",
      "Neuron 155: 0.1436508744955063\n",
      "Neuron 461: 0.14388011395931244\n",
      "Neuron 455: 0.14545896649360657\n",
      "Neuron 274: 0.1491011083126068\n",
      "Neuron 196: 0.15063567459583282\n",
      "Neuron 356: 0.15189479291439056\n",
      "Neuron 333: 0.15460176765918732\n",
      "Neuron 51: 0.1546788066625595\n",
      "Neuron 352: 0.1560298651456833\n",
      "Neuron 34: 0.1575682908296585\n",
      "Neuron 415: 0.1587308645248413\n",
      "Neuron 161: 0.16227348148822784\n",
      "Neuron 62: 0.1666472852230072\n",
      "Neuron 253: 0.16908395290374756\n",
      "Neuron 113: 0.17017413675785065\n",
      "Neuron 357: 0.1710110902786255\n",
      "Neuron 4: 0.17225539684295654\n",
      "Neuron 203: 0.172727569937706\n",
      "Neuron 462: 0.17279887199401855\n",
      "Neuron 190: 0.17285941541194916\n",
      "Neuron 290: 0.17404846847057343\n",
      "Neuron 368: 0.17425401508808136\n",
      "Neuron 327: 0.17450353503227234\n",
      "Neuron 483: 0.1745714396238327\n",
      "Neuron 364: 0.17564614117145538\n",
      "Neuron 123: 0.17787688970565796\n",
      "Neuron 490: 0.1785249263048172\n",
      "Neuron 121: 0.17896930873394012\n",
      "Neuron 255: 0.18278206884860992\n",
      "Neuron 498: 0.18365424871444702\n",
      "Neuron 232: 0.18371571600437164\n",
      "Neuron 378: 0.18426837027072906\n",
      "Neuron 399: 0.18494731187820435\n",
      "Neuron 381: 0.18511298298835754\n",
      "Neuron 210: 0.18778742849826813\n",
      "Neuron 297: 0.1880006492137909\n",
      "Neuron 396: 0.18875697255134583\n",
      "Neuron 316: 0.1890653669834137\n",
      "Neuron 2: 0.18935491144657135\n",
      "Neuron 73: 0.19218727946281433\n",
      "Neuron 363: 0.19229796528816223\n",
      "Neuron 295: 0.193171888589859\n",
      "Neuron 137: 0.19325436651706696\n",
      "Neuron 422: 0.1938171684741974\n",
      "Neuron 97: 0.1941715031862259\n",
      "Neuron 225: 0.1944730430841446\n",
      "Neuron 19: 0.1957491636276245\n",
      "Neuron 293: 0.19686582684516907\n",
      "Neuron 25: 0.19693909585475922\n",
      "Neuron 135: 0.19711318612098694\n",
      "Neuron 280: 0.19861021637916565\n",
      "Neuron 342: 0.20112282037734985\n",
      "Neuron 343: 0.20124845206737518\n",
      "Neuron 346: 0.20312561094760895\n",
      "Neuron 361: 0.2036859691143036\n",
      "Neuron 14: 0.20493176579475403\n",
      "Neuron 36: 0.20599253475666046\n",
      "Neuron 32: 0.207227423787117\n",
      "Neuron 412: 0.20928208529949188\n",
      "Neuron 479: 0.20952746272087097\n",
      "Neuron 495: 0.20985671877861023\n",
      "Neuron 214: 0.2099938690662384\n",
      "Neuron 96: 0.2102251946926117\n",
      "Neuron 248: 0.211525559425354\n",
      "Neuron 112: 0.21163713932037354\n",
      "Neuron 442: 0.21232011914253235\n",
      "Neuron 496: 0.21237634122371674\n",
      "Neuron 231: 0.21279892325401306\n",
      "Neuron 286: 0.213202565908432\n",
      "Neuron 351: 0.21404680609703064\n",
      "Neuron 68: 0.21574753522872925\n",
      "Neuron 21: 0.2157902866601944\n",
      "Neuron 331: 0.21585451066493988\n",
      "Neuron 168: 0.21636344492435455\n",
      "Neuron 82: 0.2171369343996048\n",
      "Neuron 6: 0.21950644254684448\n",
      "Neuron 423: 0.21980810165405273\n",
      "Neuron 131: 0.22065956890583038\n",
      "Neuron 499: 0.22442901134490967\n",
      "Neuron 489: 0.22563740611076355\n",
      "Neuron 13: 0.2256801724433899\n",
      "Neuron 56: 0.22601822018623352\n",
      "Neuron 257: 0.226448655128479\n",
      "Neuron 202: 0.2267688661813736\n",
      "Neuron 176: 0.22764767706394196\n",
      "Neuron 207: 0.2276596873998642\n",
      "Neuron 33: 0.22897888720035553\n",
      "Neuron 239: 0.23024851083755493\n",
      "Neuron 52: 0.23077163100242615\n",
      "Neuron 28: 0.2310183346271515\n",
      "Neuron 128: 0.2314019501209259\n",
      "Neuron 53: 0.23158442974090576\n",
      "Neuron 334: 0.23213554918766022\n",
      "Neuron 335: 0.23322893679141998\n",
      "Neuron 65: 0.2337680160999298\n",
      "Neuron 158: 0.2339581847190857\n",
      "Neuron 94: 0.23452039062976837\n",
      "Neuron 204: 0.2348780333995819\n",
      "Neuron 115: 0.23538437485694885\n",
      "Neuron 379: 0.23542802035808563\n",
      "Neuron 59: 0.23547057807445526\n",
      "Neuron 87: 0.23554380238056183\n",
      "Neuron 63: 0.2355894297361374\n",
      "Neuron 114: 0.23574985563755035\n",
      "Neuron 117: 0.23581911623477936\n",
      "Neuron 421: 0.23582331836223602\n",
      "Neuron 191: 0.2361297309398651\n",
      "Neuron 10: 0.23626665771007538\n",
      "Neuron 354: 0.2367701381444931\n",
      "Neuron 273: 0.23750434815883636\n",
      "Neuron 211: 0.23752205073833466\n",
      "Neuron 221: 0.2386658936738968\n",
      "Neuron 366: 0.23916086554527283\n",
      "Neuron 385: 0.2397996038198471\n",
      "Neuron 246: 0.2403305470943451\n",
      "Neuron 371: 0.24088148772716522\n",
      "Neuron 374: 0.2410925030708313\n",
      "Neuron 54: 0.24135901033878326\n",
      "Neuron 71: 0.24150024354457855\n",
      "Neuron 287: 0.24210374057292938\n",
      "Neuron 269: 0.24237145483493805\n",
      "Neuron 187: 0.2426326721906662\n",
      "Neuron 433: 0.24285122752189636\n",
      "Neuron 432: 0.2441679984331131\n",
      "Neuron 414: 0.24481278657913208\n",
      "Neuron 105: 0.24481935799121857\n",
      "Neuron 184: 0.24542072415351868\n",
      "Neuron 453: 0.24579407274723053\n",
      "Neuron 501: 0.24589377641677856\n",
      "Neuron 503: 0.24598976969718933\n",
      "Neuron 142: 0.24621298909187317\n",
      "Neuron 129: 0.2467256337404251\n",
      "Neuron 389: 0.24689175188541412\n",
      "Neuron 447: 0.24767117202281952\n",
      "Neuron 270: 0.2477879673242569\n",
      "Neuron 465: 0.24869507551193237\n",
      "Neuron 315: 0.2501271069049835\n",
      "Neuron 27: 0.25014030933380127\n",
      "Neuron 440: 0.2504567503929138\n",
      "Neuron 424: 0.2510521113872528\n",
      "Neuron 251: 0.2514272928237915\n",
      "Neuron 165: 0.2520202100276947\n",
      "Neuron 192: 0.2525748312473297\n",
      "Neuron 8: 0.25277116894721985\n",
      "Neuron 299: 0.2539865970611572\n",
      "Neuron 267: 0.2551422715187073\n",
      "Neuron 451: 0.25717443227767944\n",
      "Neuron 393: 0.25757503509521484\n",
      "Neuron 353: 0.2580329179763794\n",
      "Neuron 266: 0.2586001455783844\n",
      "Neuron 285: 0.25884196162223816\n",
      "Neuron 127: 0.25937509536743164\n",
      "Neuron 178: 0.2597604990005493\n",
      "Neuron 464: 0.25991931557655334\n",
      "Neuron 227: 0.26158127188682556\n",
      "Neuron 41: 0.2624463737010956\n",
      "Neuron 305: 0.26335933804512024\n",
      "Neuron 264: 0.26428043842315674\n",
      "Neuron 152: 0.2664569914340973\n",
      "Neuron 320: 0.2667054235935211\n",
      "Neuron 72: 0.2673979103565216\n",
      "Neuron 136: 0.2681732475757599\n",
      "Neuron 328: 0.26827535033226013\n",
      "Neuron 338: 0.26838430762290955\n",
      "Neuron 110: 0.2689809501171112\n",
      "Neuron 428: 0.269096702337265\n",
      "Neuron 291: 0.2693226635456085\n",
      "Neuron 277: 0.26977935433387756\n",
      "Neuron 466: 0.2699424922466278\n",
      "Neuron 256: 0.27012544870376587\n",
      "Neuron 497: 0.27035582065582275\n",
      "Neuron 397: 0.2707524597644806\n",
      "Neuron 220: 0.27113965153694153\n",
      "Neuron 169: 0.27128633856773376\n",
      "Neuron 229: 0.27134019136428833\n",
      "Neuron 44: 0.27234506607055664\n",
      "Neuron 507: 0.2725393772125244\n",
      "Neuron 272: 0.2731614410877228\n",
      "Neuron 147: 0.2734498381614685\n",
      "Neuron 206: 0.2736945152282715\n",
      "Neuron 26: 0.2738282084465027\n",
      "Neuron 67: 0.27390387654304504\n",
      "Neuron 271: 0.27585482597351074\n",
      "Neuron 22: 0.27612271904945374\n",
      "Neuron 241: 0.27654609084129333\n",
      "Neuron 50: 0.2771901786327362\n",
      "Neuron 18: 0.27720725536346436\n",
      "Neuron 445: 0.27726659178733826\n",
      "Neuron 133: 0.2774258852005005\n",
      "Neuron 370: 0.2776757478713989\n",
      "Neuron 308: 0.27919989824295044\n",
      "Neuron 348: 0.28006699681282043\n",
      "Neuron 294: 0.280295193195343\n",
      "Neuron 398: 0.2805144190788269\n",
      "Neuron 120: 0.28099969029426575\n",
      "Neuron 3: 0.2811430096626282\n",
      "Neuron 425: 0.28152918815612793\n",
      "Neuron 37: 0.2819746732711792\n",
      "Neuron 282: 0.28216567635536194\n",
      "Neuron 376: 0.2825213670730591\n",
      "Neuron 185: 0.28387877345085144\n",
      "Neuron 281: 0.2841807007789612\n",
      "Neuron 173: 0.28465476632118225\n",
      "Neuron 258: 0.28512105345726013\n",
      "Neuron 446: 0.2853947877883911\n",
      "Neuron 303: 0.2859102785587311\n",
      "Neuron 156: 0.28684237599372864\n",
      "Neuron 275: 0.2870875298976898\n",
      "Neuron 70: 0.2872597873210907\n",
      "Neuron 15: 0.2874133288860321\n",
      "Neuron 183: 0.2874830663204193\n",
      "Neuron 467: 0.28766146302223206\n",
      "Neuron 167: 0.2877616584300995\n",
      "Neuron 387: 0.2889460027217865\n",
      "Neuron 107: 0.2893062233924866\n",
      "Neuron 288: 0.28933587670326233\n",
      "Neuron 457: 0.2910957336425781\n",
      "Neuron 444: 0.2911733090877533\n",
      "Neuron 429: 0.29235661029815674\n",
      "Neuron 441: 0.2924552857875824\n",
      "Neuron 194: 0.2934361696243286\n",
      "Neuron 130: 0.293526828289032\n",
      "Neuron 472: 0.29426148533821106\n",
      "Neuron 7: 0.29456084966659546\n",
      "Neuron 226: 0.29470381140708923\n",
      "Neuron 40: 0.295459121465683\n",
      "Neuron 55: 0.2954661250114441\n",
      "Neuron 212: 0.2956252694129944\n",
      "Neuron 417: 0.29587262868881226\n",
      "Neuron 448: 0.2963067293167114\n",
      "Neuron 0: 0.2965558171272278\n",
      "Neuron 318: 0.29655957221984863\n",
      "Neuron 259: 0.29752835631370544\n",
      "Neuron 86: 0.2978754937648773\n",
      "Neuron 262: 0.2987230122089386\n",
      "Neuron 222: 0.29879674315452576\n",
      "Neuron 9: 0.2988644540309906\n",
      "Neuron 69: 0.2994386851787567\n",
      "Neuron 487: 0.30004024505615234\n",
      "Neuron 245: 0.3005286753177643\n",
      "Neuron 469: 0.30162423849105835\n",
      "Neuron 149: 0.3016277253627777\n",
      "Neuron 164: 0.30207642912864685\n",
      "Neuron 111: 0.302103191614151\n",
      "Neuron 390: 0.3025661110877991\n",
      "Neuron 314: 0.3032234013080597\n",
      "Neuron 458: 0.30537906289100647\n",
      "Neuron 17: 0.3055756092071533\n",
      "Neuron 145: 0.306522935628891\n",
      "Neuron 484: 0.3066709637641907\n",
      "Neuron 319: 0.3072274625301361\n",
      "Neuron 108: 0.3076227903366089\n",
      "Neuron 375: 0.30772754549980164\n",
      "Neuron 219: 0.30812013149261475\n",
      "Neuron 252: 0.30819061398506165\n",
      "Neuron 47: 0.30863332748413086\n",
      "Neuron 509: 0.30913516879081726\n",
      "Neuron 443: 0.30997607111930847\n",
      "Neuron 279: 0.3111061751842499\n",
      "Neuron 140: 0.31123194098472595\n",
      "Neuron 406: 0.3112490177154541\n",
      "Neuron 298: 0.3118448853492737\n",
      "Neuron 200: 0.31278809905052185\n",
      "Neuron 449: 0.31315916776657104\n",
      "Neuron 101: 0.31332850456237793\n",
      "Neuron 283: 0.31348302960395813\n",
      "Neuron 160: 0.3137032091617584\n",
      "Neuron 488: 0.31393152475357056\n",
      "Neuron 341: 0.3143827021121979\n",
      "Neuron 30: 0.31509360671043396\n",
      "Neuron 478: 0.3162781000137329\n",
      "Neuron 217: 0.31740880012512207\n",
      "Neuron 181: 0.31751230359077454\n",
      "Neuron 197: 0.31816279888153076\n",
      "Neuron 408: 0.31839239597320557\n",
      "Neuron 382: 0.319051057100296\n",
      "Neuron 410: 0.319209486246109\n",
      "Neuron 29: 0.31932538747787476\n",
      "Neuron 411: 0.3193650245666504\n",
      "Neuron 143: 0.3194083273410797\n",
      "Neuron 355: 0.31948885321617126\n",
      "Neuron 508: 0.31965360045433044\n",
      "Neuron 99: 0.3200768530368805\n",
      "Neuron 38: 0.32041141390800476\n",
      "Neuron 437: 0.3208141326904297\n",
      "Neuron 126: 0.32174748182296753\n",
      "Neuron 242: 0.32234472036361694\n",
      "Neuron 391: 0.3227821886539459\n",
      "Neuron 78: 0.32281234860420227\n",
      "Neuron 505: 0.32302460074424744\n",
      "Neuron 468: 0.32328155636787415\n",
      "Neuron 138: 0.32335567474365234\n",
      "Neuron 88: 0.3234195113182068\n",
      "Neuron 166: 0.3238586187362671\n",
      "Neuron 420: 0.3241025507450104\n",
      "Neuron 64: 0.32507914304733276\n",
      "Neuron 284: 0.3258497416973114\n",
      "Neuron 215: 0.32630008459091187\n",
      "Neuron 224: 0.3272240459918976\n",
      "Neuron 244: 0.32837432622909546\n",
      "Neuron 339: 0.328900545835495\n",
      "Neuron 301: 0.3296315371990204\n",
      "Neuron 48: 0.331595778465271\n",
      "Neuron 124: 0.3330608010292053\n",
      "Neuron 153: 0.3331924378871918\n",
      "Neuron 485: 0.33363571763038635\n",
      "Neuron 337: 0.33407384157180786\n",
      "Neuron 175: 0.3341370224952698\n",
      "Neuron 139: 0.33454540371894836\n",
      "Neuron 43: 0.335083931684494\n",
      "Neuron 463: 0.33555981516838074\n",
      "Neuron 276: 0.3366791009902954\n",
      "Neuron 79: 0.3367172181606293\n",
      "Neuron 388: 0.33709731698036194\n",
      "Neuron 436: 0.337127149105072\n",
      "Neuron 76: 0.3372892439365387\n",
      "Neuron 157: 0.337322860956192\n",
      "Neuron 24: 0.3373532295227051\n",
      "Neuron 434: 0.3375682532787323\n",
      "Neuron 384: 0.3379075527191162\n",
      "Neuron 302: 0.33807116746902466\n",
      "Neuron 367: 0.3397890627384186\n",
      "Neuron 510: 0.34135082364082336\n",
      "Neuron 325: 0.3414648473262787\n",
      "Neuron 234: 0.34181827306747437\n",
      "Neuron 89: 0.34214553236961365\n",
      "Neuron 85: 0.3432258367538452\n",
      "Neuron 506: 0.3435540795326233\n",
      "Neuron 347: 0.3460570275783539\n",
      "Neuron 480: 0.34626317024230957\n",
      "Neuron 249: 0.34634116291999817\n",
      "Neuron 329: 0.3463641107082367\n",
      "Neuron 213: 0.3465249240398407\n",
      "Neuron 209: 0.3471454977989197\n",
      "Neuron 377: 0.3476618528366089\n",
      "Neuron 84: 0.34851783514022827\n",
      "Neuron 39: 0.3505794107913971\n",
      "Neuron 11: 0.35140570998191833\n",
      "Neuron 23: 0.3514765501022339\n",
      "Neuron 313: 0.3516184389591217\n",
      "Neuron 405: 0.3525753617286682\n",
      "Neuron 312: 0.35342392325401306\n",
      "Neuron 268: 0.35427480936050415\n",
      "Neuron 57: 0.3548987805843353\n",
      "Neuron 322: 0.35626038908958435\n",
      "Neuron 162: 0.35672613978385925\n",
      "Neuron 340: 0.3572861850261688\n",
      "Neuron 188: 0.35761401057243347\n",
      "Neuron 151: 0.3579856753349304\n",
      "Neuron 31: 0.3581569790840149\n",
      "Neuron 310: 0.3582511842250824\n",
      "Neuron 452: 0.3584277629852295\n",
      "Neuron 49: 0.35937657952308655\n",
      "Neuron 401: 0.3599841892719269\n",
      "Neuron 265: 0.36181768774986267\n",
      "Neuron 180: 0.3619261384010315\n",
      "Neuron 223: 0.36312708258628845\n",
      "Neuron 91: 0.36390289664268494\n",
      "Neuron 292: 0.3641682267189026\n",
      "Neuron 306: 0.36418914794921875\n",
      "Neuron 12: 0.364268958568573\n",
      "Neuron 473: 0.3642691373825073\n",
      "Neuron 407: 0.36547160148620605\n",
      "Neuron 332: 0.3661547601222992\n",
      "Neuron 146: 0.36793166399002075\n",
      "Neuron 435: 0.36886003613471985\n",
      "Neuron 58: 0.3689996302127838\n",
      "Neuron 237: 0.3695108890533447\n",
      "Neuron 195: 0.37141475081443787\n",
      "Neuron 83: 0.3718357980251312\n",
      "Neuron 260: 0.37206152081489563\n",
      "Neuron 474: 0.37217840552330017\n",
      "Neuron 235: 0.3726668059825897\n",
      "Neuron 477: 0.37287086248397827\n",
      "Neuron 16: 0.3732532858848572\n",
      "Neuron 403: 0.37327325344085693\n",
      "Neuron 304: 0.37351131439208984\n",
      "Neuron 109: 0.37495186924934387\n",
      "Neuron 289: 0.3765546977519989\n",
      "Neuron 230: 0.3776387870311737\n",
      "Neuron 106: 0.3781934380531311\n",
      "Neuron 171: 0.3783949613571167\n",
      "Neuron 182: 0.378714919090271\n",
      "Neuron 216: 0.3789140284061432\n",
      "Neuron 261: 0.3797398507595062\n",
      "Neuron 208: 0.381296306848526\n",
      "Neuron 345: 0.3814861476421356\n",
      "Neuron 35: 0.3836861848831177\n",
      "Neuron 150: 0.3841535747051239\n",
      "Neuron 228: 0.38487979769706726\n",
      "Neuron 358: 0.38577932119369507\n",
      "Neuron 486: 0.3865497410297394\n",
      "Neuron 326: 0.3866361975669861\n",
      "Neuron 431: 0.38690313696861267\n",
      "Neuron 317: 0.3873938024044037\n",
      "Neuron 402: 0.3880709707736969\n",
      "Neuron 103: 0.38808131217956543\n",
      "Neuron 238: 0.3888736963272095\n",
      "Neuron 400: 0.389128178358078\n",
      "Neuron 154: 0.3896784782409668\n",
      "Neuron 278: 0.3898181915283203\n",
      "Neuron 360: 0.390185683965683\n",
      "Neuron 359: 0.390264093875885\n",
      "Neuron 475: 0.3913804590702057\n",
      "Neuron 350: 0.3918182849884033\n",
      "Neuron 372: 0.3923821747303009\n",
      "Neuron 386: 0.3937745988368988\n",
      "Neuron 300: 0.3939657211303711\n",
      "Neuron 430: 0.39459228515625\n",
      "Neuron 426: 0.39519503712654114\n",
      "Neuron 482: 0.3953505754470825\n",
      "Neuron 233: 0.397664874792099\n",
      "Neuron 476: 0.39814597368240356\n",
      "Neuron 392: 0.39927542209625244\n",
      "Neuron 122: 0.4006769061088562\n",
      "Neuron 205: 0.4007691740989685\n",
      "Neuron 460: 0.4032955467700958\n",
      "Neuron 450: 0.4042873978614807\n",
      "Neuron 439: 0.4044806659221649\n",
      "Neuron 118: 0.40450718998908997\n",
      "Neuron 323: 0.41085493564605713\n",
      "Neuron 74: 0.4110630750656128\n",
      "Neuron 500: 0.4121305048465729\n",
      "Neuron 100: 0.4148608446121216\n",
      "Neuron 395: 0.4161345660686493\n",
      "Neuron 511: 0.4163200557231903\n",
      "Neuron 81: 0.41707783937454224\n",
      "Neuron 324: 0.41719233989715576\n",
      "Neuron 492: 0.41763588786125183\n",
      "Neuron 179: 0.4177744686603546\n",
      "Neuron 243: 0.42175644636154175\n",
      "Neuron 170: 0.4232988655567169\n",
      "Neuron 132: 0.42443573474884033\n",
      "Neuron 116: 0.4244998097419739\n",
      "Neuron 60: 0.42517030239105225\n",
      "Neuron 263: 0.42575499415397644\n",
      "Neuron 504: 0.42693114280700684\n",
      "Neuron 438: 0.42736944556236267\n",
      "Neuron 199: 0.42850425839424133\n",
      "Neuron 144: 0.42927369475364685\n",
      "Neuron 20: 0.4303515553474426\n",
      "Neuron 174: 0.43420571088790894\n",
      "Neuron 93: 0.4362454116344452\n",
      "Neuron 134: 0.43868574500083923\n",
      "Neuron 418: 0.44064706563949585\n",
      "Neuron 186: 0.44402486085891724\n",
      "Neuron 394: 0.44517749547958374\n",
      "Neuron 349: 0.4479977488517761\n",
      "Neuron 493: 0.44874173402786255\n",
      "Neuron 159: 0.4489138722419739\n",
      "Neuron 46: 0.44942134618759155\n",
      "Neuron 254: 0.4505472779273987\n",
      "Neuron 413: 0.45445016026496887\n",
      "Neuron 344: 0.4552619159221649\n",
      "Neuron 5: 0.4553469717502594\n",
      "Neuron 481: 0.4553758203983307\n",
      "Neuron 119: 0.45690053701400757\n",
      "Neuron 177: 0.45765024423599243\n",
      "Neuron 321: 0.4639391005039215\n",
      "Neuron 373: 0.46506568789482117\n",
      "Neuron 369: 0.47145459055900574\n",
      "Neuron 362: 0.4721173346042633\n",
      "Neuron 502: 0.4783186912536621\n",
      "Neuron 66: 0.47905316948890686\n",
      "Neuron 201: 0.4793380796909332\n",
      "Neuron 102: 0.48547065258026123\n",
      "Neuron 309: 0.5046746134757996\n",
      "Neuron 416: 0.505813717842102\n",
      "Neuron 141: 0.5066510438919067\n",
      "Neuron 1: 0.5277276635169983\n",
      "Neuron 45: 0.5354892611503601\n",
      "Neuron 409: 0.5502686500549316\n",
      "Neuron 459: 0.5531987547874451\n",
      "Neuron 193: 0.5629692673683167\n",
      "Neuron 80: 0.5778976082801819\n",
      "Neuron 494: 0.5890339612960815\n",
      "Neuron 456: 0.6035900115966797\n",
      "Neuron 365: 0.6053479313850403\n"
     ]
    }
   ],
   "source": [
    "# 对平均激活值进行排序\n",
    "average_activations = tf.reduce_mean(conv_outputs, axis=(0,1,2)) # 计算每个神经元在整个测试数据集上的平均激活值\n",
    "sorted_indices = tf.argsort(average_activations, direction='ASCENDING') # 对平均激活值进行排序\n",
    "for i in range(len(sorted_indices)): #打印排序后的神经元及其对应的平均激活值\n",
    "    print(f\"Neuron {sorted_indices[i]}: {average_activations[sorted_indices[i]]}\")\n",
    "    # 打印观察每个神经元在整个测试数据集上的平均激活值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d293c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 单次剪枝代码\n",
    "# sorted_indices = tf.argsort(average_activations, direction='ASCENDING') # 对平均激活值进行排序 argsort函数返回的是数组值从小到大的索引值\n",
    "# # sorted_indices\n",
    "# # len(sorted_indices)\n",
    "# K = 1 # 要剪枝的神经元数\n",
    "# last_conv_layer = model.layers[-12]\n",
    "# weights, biases = last_conv_layer.get_weights()\n",
    "# for i in range(0, K):\n",
    "#     neuron_index = sorted_indices[i]\n",
    "#     weights[:,:,:,neuron_index] = 0 # 将该神经元的权重设为0\n",
    "#     biases[neuron_index] = 0 # 将该神经元的偏置设为0\n",
    "# last_conv_layer.set_weights([weights, biases]) # 更新最后一层卷积层的权重和偏置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bab3e129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuron 236: 0.0\n",
      "Neuron 383: 0.05992547422647476\n",
      "Neuron 125: 0.07034046947956085\n",
      "Neuron 491: 0.08466646820306778\n",
      "Neuron 218: 0.08590062707662582\n",
      "Neuron 92: 0.08756137639284134\n",
      "Neuron 380: 0.10096488893032074\n",
      "Neuron 427: 0.10129434615373611\n",
      "Neuron 104: 0.10306920111179352\n",
      "Neuron 454: 0.10644809901714325\n",
      "Neuron 61: 0.10692503303289413\n",
      "Neuron 336: 0.11001578718423843\n",
      "Neuron 250: 0.11110815405845642\n",
      "Neuron 172: 0.11362634599208832\n",
      "Neuron 307: 0.11739332228899002\n",
      "Neuron 148: 0.12002052366733551\n",
      "Neuron 247: 0.12507620453834534\n",
      "Neuron 198: 0.12552356719970703\n",
      "Neuron 419: 0.12754957377910614\n",
      "Neuron 42: 0.1288086473941803\n",
      "Neuron 311: 0.12914273142814636\n",
      "Neuron 77: 0.1298746019601822\n",
      "Neuron 75: 0.13046099245548248\n",
      "Neuron 471: 0.1351509839296341\n",
      "Neuron 470: 0.13604474067687988\n",
      "Neuron 296: 0.1363120824098587\n",
      "Neuron 404: 0.1368200033903122\n",
      "Neuron 95: 0.1377684772014618\n",
      "Neuron 240: 0.13837897777557373\n",
      "Neuron 98: 0.1384437531232834\n",
      "Neuron 90: 0.1385039985179901\n",
      "Neuron 189: 0.1391487419605255\n",
      "Neuron 163: 0.13957670331001282\n",
      "Neuron 330: 0.13968823850154877\n",
      "Neuron 155: 0.1436508744955063\n",
      "Neuron 461: 0.14388011395931244\n",
      "Neuron 455: 0.14545896649360657\n",
      "Neuron 274: 0.1491011083126068\n",
      "Neuron 196: 0.15063567459583282\n",
      "Neuron 356: 0.15189479291439056\n",
      "Neuron 333: 0.15460176765918732\n",
      "Neuron 51: 0.1546788066625595\n",
      "Neuron 352: 0.1560298651456833\n",
      "Neuron 34: 0.1575682908296585\n",
      "Neuron 415: 0.1587308645248413\n",
      "Neuron 161: 0.16227348148822784\n",
      "Neuron 62: 0.1666472852230072\n",
      "Neuron 253: 0.16908395290374756\n",
      "Neuron 113: 0.17017413675785065\n",
      "Neuron 357: 0.1710110902786255\n",
      "Neuron 4: 0.17225539684295654\n",
      "Neuron 203: 0.172727569937706\n",
      "Neuron 462: 0.17279887199401855\n",
      "Neuron 190: 0.17285941541194916\n",
      "Neuron 290: 0.17404846847057343\n",
      "Neuron 368: 0.17425401508808136\n",
      "Neuron 327: 0.17450353503227234\n",
      "Neuron 483: 0.1745714396238327\n",
      "Neuron 364: 0.17564614117145538\n",
      "Neuron 123: 0.17787688970565796\n",
      "Neuron 490: 0.1785249263048172\n",
      "Neuron 121: 0.17896930873394012\n",
      "Neuron 255: 0.18278206884860992\n",
      "Neuron 498: 0.18365424871444702\n",
      "Neuron 232: 0.18371571600437164\n",
      "Neuron 378: 0.18426837027072906\n",
      "Neuron 399: 0.18494731187820435\n",
      "Neuron 381: 0.18511298298835754\n",
      "Neuron 210: 0.18778742849826813\n",
      "Neuron 297: 0.1880006492137909\n",
      "Neuron 396: 0.18875697255134583\n",
      "Neuron 316: 0.1890653669834137\n",
      "Neuron 2: 0.18935491144657135\n",
      "Neuron 73: 0.19218727946281433\n",
      "Neuron 363: 0.19229796528816223\n",
      "Neuron 295: 0.193171888589859\n",
      "Neuron 137: 0.19325436651706696\n",
      "Neuron 422: 0.1938171684741974\n",
      "Neuron 97: 0.1941715031862259\n",
      "Neuron 225: 0.1944730430841446\n",
      "Neuron 19: 0.1957491636276245\n",
      "Neuron 293: 0.19686582684516907\n",
      "Neuron 25: 0.19693909585475922\n",
      "Neuron 135: 0.19711318612098694\n",
      "Neuron 280: 0.19861021637916565\n",
      "Neuron 342: 0.20112282037734985\n",
      "Neuron 343: 0.20124845206737518\n",
      "Neuron 346: 0.20312561094760895\n",
      "Neuron 361: 0.2036859691143036\n",
      "Neuron 14: 0.20493176579475403\n",
      "Neuron 36: 0.20599253475666046\n",
      "Neuron 32: 0.207227423787117\n",
      "Neuron 412: 0.20928208529949188\n",
      "Neuron 479: 0.20952746272087097\n",
      "Neuron 495: 0.20985671877861023\n",
      "Neuron 214: 0.2099938690662384\n",
      "Neuron 96: 0.2102251946926117\n",
      "Neuron 248: 0.211525559425354\n",
      "Neuron 112: 0.21163713932037354\n",
      "Neuron 442: 0.21232011914253235\n",
      "Neuron 496: 0.21237634122371674\n",
      "Neuron 231: 0.21279892325401306\n",
      "Neuron 286: 0.213202565908432\n",
      "Neuron 351: 0.21404680609703064\n",
      "Neuron 68: 0.21574753522872925\n",
      "Neuron 21: 0.2157902866601944\n",
      "Neuron 331: 0.21585451066493988\n",
      "Neuron 168: 0.21636344492435455\n",
      "Neuron 82: 0.2171369343996048\n",
      "Neuron 6: 0.21950644254684448\n",
      "Neuron 423: 0.21980810165405273\n",
      "Neuron 131: 0.22065956890583038\n",
      "Neuron 499: 0.22442901134490967\n",
      "Neuron 489: 0.22563740611076355\n",
      "Neuron 13: 0.2256801724433899\n",
      "Neuron 56: 0.22601822018623352\n",
      "Neuron 257: 0.226448655128479\n",
      "Neuron 202: 0.2267688661813736\n",
      "Neuron 176: 0.22764767706394196\n",
      "Neuron 207: 0.2276596873998642\n",
      "Neuron 33: 0.22897888720035553\n",
      "Neuron 239: 0.23024851083755493\n",
      "Neuron 52: 0.23077163100242615\n",
      "Neuron 28: 0.2310183346271515\n",
      "Neuron 128: 0.2314019501209259\n",
      "Neuron 53: 0.23158442974090576\n",
      "Neuron 334: 0.23213554918766022\n",
      "Neuron 335: 0.23322893679141998\n",
      "Neuron 65: 0.2337680160999298\n",
      "Neuron 158: 0.2339581847190857\n",
      "Neuron 94: 0.23452039062976837\n",
      "Neuron 204: 0.2348780333995819\n",
      "Neuron 115: 0.23538437485694885\n",
      "Neuron 379: 0.23542802035808563\n",
      "Neuron 59: 0.23547057807445526\n",
      "Neuron 87: 0.23554380238056183\n",
      "Neuron 63: 0.2355894297361374\n",
      "Neuron 114: 0.23574985563755035\n",
      "Neuron 117: 0.23581911623477936\n",
      "Neuron 421: 0.23582331836223602\n",
      "Neuron 191: 0.2361297309398651\n",
      "Neuron 10: 0.23626665771007538\n",
      "Neuron 354: 0.2367701381444931\n",
      "Neuron 273: 0.23750434815883636\n",
      "Neuron 211: 0.23752205073833466\n",
      "Neuron 221: 0.2386658936738968\n",
      "Neuron 366: 0.23916086554527283\n",
      "Neuron 385: 0.2397996038198471\n",
      "Neuron 246: 0.2403305470943451\n",
      "Neuron 371: 0.24088148772716522\n",
      "Neuron 374: 0.2410925030708313\n",
      "Neuron 54: 0.24135901033878326\n",
      "Neuron 71: 0.24150024354457855\n",
      "Neuron 287: 0.24210374057292938\n",
      "Neuron 269: 0.24237145483493805\n",
      "Neuron 187: 0.2426326721906662\n",
      "Neuron 433: 0.24285122752189636\n",
      "Neuron 432: 0.2441679984331131\n",
      "Neuron 414: 0.24481278657913208\n",
      "Neuron 105: 0.24481935799121857\n",
      "Neuron 184: 0.24542072415351868\n",
      "Neuron 453: 0.24579407274723053\n",
      "Neuron 501: 0.24589377641677856\n",
      "Neuron 503: 0.24598976969718933\n",
      "Neuron 142: 0.24621298909187317\n",
      "Neuron 129: 0.2467256337404251\n",
      "Neuron 389: 0.24689175188541412\n",
      "Neuron 447: 0.24767117202281952\n",
      "Neuron 270: 0.2477879673242569\n",
      "Neuron 465: 0.24869507551193237\n",
      "Neuron 315: 0.2501271069049835\n",
      "Neuron 27: 0.25014030933380127\n",
      "Neuron 440: 0.2504567503929138\n",
      "Neuron 424: 0.2510521113872528\n",
      "Neuron 251: 0.2514272928237915\n",
      "Neuron 165: 0.2520202100276947\n",
      "Neuron 192: 0.2525748312473297\n",
      "Neuron 8: 0.25277116894721985\n",
      "Neuron 299: 0.2539865970611572\n",
      "Neuron 267: 0.2551422715187073\n",
      "Neuron 451: 0.25717443227767944\n",
      "Neuron 393: 0.25757503509521484\n",
      "Neuron 353: 0.2580329179763794\n",
      "Neuron 266: 0.2586001455783844\n",
      "Neuron 285: 0.25884196162223816\n",
      "Neuron 127: 0.25937509536743164\n",
      "Neuron 178: 0.2597604990005493\n",
      "Neuron 464: 0.25991931557655334\n",
      "Neuron 227: 0.26158127188682556\n",
      "Neuron 41: 0.2624463737010956\n",
      "Neuron 305: 0.26335933804512024\n",
      "Neuron 264: 0.26428043842315674\n",
      "Neuron 152: 0.2664569914340973\n",
      "Neuron 320: 0.2667054235935211\n",
      "Neuron 72: 0.2673979103565216\n",
      "Neuron 136: 0.2681732475757599\n",
      "Neuron 328: 0.26827535033226013\n",
      "Neuron 338: 0.26838430762290955\n",
      "Neuron 110: 0.2689809501171112\n",
      "Neuron 428: 0.269096702337265\n",
      "Neuron 291: 0.2693226635456085\n",
      "Neuron 277: 0.26977935433387756\n",
      "Neuron 466: 0.2699424922466278\n",
      "Neuron 256: 0.27012544870376587\n",
      "Neuron 497: 0.27035582065582275\n",
      "Neuron 397: 0.2707524597644806\n",
      "Neuron 220: 0.27113965153694153\n",
      "Neuron 169: 0.27128633856773376\n",
      "Neuron 229: 0.27134019136428833\n",
      "Neuron 44: 0.27234506607055664\n",
      "Neuron 507: 0.2725393772125244\n",
      "Neuron 272: 0.2731614410877228\n",
      "Neuron 147: 0.2734498381614685\n",
      "Neuron 206: 0.2736945152282715\n",
      "Neuron 26: 0.2738282084465027\n",
      "Neuron 67: 0.27390387654304504\n",
      "Neuron 271: 0.27585482597351074\n",
      "Neuron 22: 0.27612271904945374\n",
      "Neuron 241: 0.27654609084129333\n",
      "Neuron 50: 0.2771901786327362\n",
      "Neuron 18: 0.27720725536346436\n",
      "Neuron 445: 0.27726659178733826\n",
      "Neuron 133: 0.2774258852005005\n",
      "Neuron 370: 0.2776757478713989\n",
      "Neuron 308: 0.27919989824295044\n",
      "Neuron 348: 0.28006699681282043\n",
      "Neuron 294: 0.280295193195343\n",
      "Neuron 398: 0.2805144190788269\n",
      "Neuron 120: 0.28099969029426575\n",
      "Neuron 3: 0.2811430096626282\n",
      "Neuron 425: 0.28152918815612793\n",
      "Neuron 37: 0.2819746732711792\n",
      "Neuron 282: 0.28216567635536194\n",
      "Neuron 376: 0.2825213670730591\n",
      "Neuron 185: 0.28387877345085144\n",
      "Neuron 281: 0.2841807007789612\n",
      "Neuron 173: 0.28465476632118225\n",
      "Neuron 258: 0.28512105345726013\n",
      "Neuron 446: 0.2853947877883911\n",
      "Neuron 303: 0.2859102785587311\n",
      "Neuron 156: 0.28684237599372864\n",
      "Neuron 275: 0.2870875298976898\n",
      "Neuron 70: 0.2872597873210907\n",
      "Neuron 15: 0.2874133288860321\n",
      "Neuron 183: 0.2874830663204193\n",
      "Neuron 467: 0.28766146302223206\n",
      "Neuron 167: 0.2877616584300995\n",
      "Neuron 387: 0.2889460027217865\n",
      "Neuron 107: 0.2893062233924866\n",
      "Neuron 288: 0.28933587670326233\n",
      "Neuron 457: 0.2910957336425781\n",
      "Neuron 444: 0.2911733090877533\n",
      "Neuron 429: 0.29235661029815674\n",
      "Neuron 441: 0.2924552857875824\n",
      "Neuron 194: 0.2934361696243286\n",
      "Neuron 130: 0.293526828289032\n",
      "Neuron 472: 0.29426148533821106\n",
      "Neuron 7: 0.29456084966659546\n",
      "Neuron 226: 0.29470381140708923\n",
      "Neuron 40: 0.295459121465683\n",
      "Neuron 55: 0.2954661250114441\n",
      "Neuron 212: 0.2956252694129944\n",
      "Neuron 417: 0.29587262868881226\n",
      "Neuron 448: 0.2963067293167114\n",
      "Neuron 0: 0.2965558171272278\n",
      "Neuron 318: 0.29655957221984863\n",
      "Neuron 259: 0.29752835631370544\n",
      "Neuron 86: 0.2978754937648773\n",
      "Neuron 262: 0.2987230122089386\n",
      "Neuron 222: 0.29879674315452576\n",
      "Neuron 9: 0.2988644540309906\n",
      "Neuron 69: 0.2994386851787567\n",
      "Neuron 487: 0.30004024505615234\n",
      "Neuron 245: 0.3005286753177643\n",
      "Neuron 469: 0.30162423849105835\n",
      "Neuron 149: 0.3016277253627777\n",
      "Neuron 164: 0.30207642912864685\n",
      "Neuron 111: 0.302103191614151\n",
      "Neuron 390: 0.3025661110877991\n",
      "Neuron 314: 0.3032234013080597\n",
      "Neuron 458: 0.30537906289100647\n",
      "Neuron 17: 0.3055756092071533\n",
      "Neuron 145: 0.306522935628891\n",
      "Neuron 484: 0.3066709637641907\n",
      "Neuron 319: 0.3072274625301361\n",
      "Neuron 108: 0.3076227903366089\n",
      "Neuron 375: 0.30772754549980164\n",
      "Neuron 219: 0.30812013149261475\n",
      "Neuron 252: 0.30819061398506165\n",
      "Neuron 47: 0.30863332748413086\n",
      "Neuron 509: 0.30913516879081726\n",
      "Neuron 443: 0.30997607111930847\n",
      "Neuron 279: 0.3111061751842499\n",
      "Neuron 140: 0.31123194098472595\n",
      "Neuron 406: 0.3112490177154541\n",
      "Neuron 298: 0.3118448853492737\n",
      "Neuron 200: 0.31278809905052185\n",
      "Neuron 449: 0.31315916776657104\n",
      "Neuron 101: 0.31332850456237793\n",
      "Neuron 283: 0.31348302960395813\n",
      "Neuron 160: 0.3137032091617584\n",
      "Neuron 488: 0.31393152475357056\n",
      "Neuron 341: 0.3143827021121979\n",
      "Neuron 30: 0.31509360671043396\n",
      "Neuron 478: 0.3162781000137329\n",
      "Neuron 217: 0.31740880012512207\n",
      "Neuron 181: 0.31751230359077454\n",
      "Neuron 197: 0.31816279888153076\n",
      "Neuron 408: 0.31839239597320557\n",
      "Neuron 382: 0.319051057100296\n",
      "Neuron 410: 0.319209486246109\n",
      "Neuron 29: 0.31932538747787476\n",
      "Neuron 411: 0.3193650245666504\n",
      "Neuron 143: 0.3194083273410797\n",
      "Neuron 355: 0.31948885321617126\n",
      "Neuron 508: 0.31965360045433044\n",
      "Neuron 99: 0.3200768530368805\n",
      "Neuron 38: 0.32041141390800476\n",
      "Neuron 437: 0.3208141326904297\n",
      "Neuron 126: 0.32174748182296753\n",
      "Neuron 242: 0.32234472036361694\n",
      "Neuron 391: 0.3227821886539459\n",
      "Neuron 78: 0.32281234860420227\n",
      "Neuron 505: 0.32302460074424744\n",
      "Neuron 468: 0.32328155636787415\n",
      "Neuron 138: 0.32335567474365234\n",
      "Neuron 88: 0.3234195113182068\n",
      "Neuron 166: 0.3238586187362671\n",
      "Neuron 420: 0.3241025507450104\n",
      "Neuron 64: 0.32507914304733276\n",
      "Neuron 284: 0.3258497416973114\n",
      "Neuron 215: 0.32630008459091187\n",
      "Neuron 224: 0.3272240459918976\n",
      "Neuron 244: 0.32837432622909546\n",
      "Neuron 339: 0.328900545835495\n",
      "Neuron 301: 0.3296315371990204\n",
      "Neuron 48: 0.331595778465271\n",
      "Neuron 124: 0.3330608010292053\n",
      "Neuron 153: 0.3331924378871918\n",
      "Neuron 485: 0.33363571763038635\n",
      "Neuron 337: 0.33407384157180786\n",
      "Neuron 175: 0.3341370224952698\n",
      "Neuron 139: 0.33454540371894836\n",
      "Neuron 43: 0.335083931684494\n",
      "Neuron 463: 0.33555981516838074\n",
      "Neuron 276: 0.3366791009902954\n",
      "Neuron 79: 0.3367172181606293\n",
      "Neuron 388: 0.33709731698036194\n",
      "Neuron 436: 0.337127149105072\n",
      "Neuron 76: 0.3372892439365387\n",
      "Neuron 157: 0.337322860956192\n",
      "Neuron 24: 0.3373532295227051\n",
      "Neuron 434: 0.3375682532787323\n",
      "Neuron 384: 0.3379075527191162\n",
      "Neuron 302: 0.33807116746902466\n",
      "Neuron 367: 0.3397890627384186\n",
      "Neuron 510: 0.34135082364082336\n",
      "Neuron 325: 0.3414648473262787\n",
      "Neuron 234: 0.34181827306747437\n",
      "Neuron 89: 0.34214553236961365\n",
      "Neuron 85: 0.3432258367538452\n",
      "Neuron 506: 0.3435540795326233\n",
      "Neuron 347: 0.3460570275783539\n",
      "Neuron 480: 0.34626317024230957\n",
      "Neuron 249: 0.34634116291999817\n",
      "Neuron 329: 0.3463641107082367\n",
      "Neuron 213: 0.3465249240398407\n",
      "Neuron 209: 0.3471454977989197\n",
      "Neuron 377: 0.3476618528366089\n",
      "Neuron 84: 0.34851783514022827\n",
      "Neuron 39: 0.3505794107913971\n",
      "Neuron 11: 0.35140570998191833\n",
      "Neuron 23: 0.3514765501022339\n",
      "Neuron 313: 0.3516184389591217\n",
      "Neuron 405: 0.3525753617286682\n",
      "Neuron 312: 0.35342392325401306\n",
      "Neuron 268: 0.35427480936050415\n",
      "Neuron 57: 0.3548987805843353\n",
      "Neuron 322: 0.35626038908958435\n",
      "Neuron 162: 0.35672613978385925\n",
      "Neuron 340: 0.3572861850261688\n",
      "Neuron 188: 0.35761401057243347\n",
      "Neuron 151: 0.3579856753349304\n",
      "Neuron 31: 0.3581569790840149\n",
      "Neuron 310: 0.3582511842250824\n",
      "Neuron 452: 0.3584277629852295\n",
      "Neuron 49: 0.35937657952308655\n",
      "Neuron 401: 0.3599841892719269\n",
      "Neuron 265: 0.36181768774986267\n",
      "Neuron 180: 0.3619261384010315\n",
      "Neuron 223: 0.36312708258628845\n",
      "Neuron 91: 0.36390289664268494\n",
      "Neuron 292: 0.3641682267189026\n",
      "Neuron 306: 0.36418914794921875\n",
      "Neuron 12: 0.364268958568573\n",
      "Neuron 473: 0.3642691373825073\n",
      "Neuron 407: 0.36547160148620605\n",
      "Neuron 332: 0.3661547601222992\n",
      "Neuron 146: 0.36793166399002075\n",
      "Neuron 435: 0.36886003613471985\n",
      "Neuron 58: 0.3689996302127838\n",
      "Neuron 237: 0.3695108890533447\n",
      "Neuron 195: 0.37141475081443787\n",
      "Neuron 83: 0.3718357980251312\n",
      "Neuron 260: 0.37206152081489563\n",
      "Neuron 474: 0.37217840552330017\n",
      "Neuron 235: 0.3726668059825897\n",
      "Neuron 477: 0.37287086248397827\n",
      "Neuron 16: 0.3732532858848572\n",
      "Neuron 403: 0.37327325344085693\n",
      "Neuron 304: 0.37351131439208984\n",
      "Neuron 109: 0.37495186924934387\n",
      "Neuron 289: 0.3765546977519989\n",
      "Neuron 230: 0.3776387870311737\n",
      "Neuron 106: 0.3781934380531311\n",
      "Neuron 171: 0.3783949613571167\n",
      "Neuron 182: 0.378714919090271\n",
      "Neuron 216: 0.3789140284061432\n",
      "Neuron 261: 0.3797398507595062\n",
      "Neuron 208: 0.381296306848526\n",
      "Neuron 345: 0.3814861476421356\n",
      "Neuron 35: 0.3836861848831177\n",
      "Neuron 150: 0.3841535747051239\n",
      "Neuron 228: 0.38487979769706726\n",
      "Neuron 358: 0.38577932119369507\n",
      "Neuron 486: 0.3865497410297394\n",
      "Neuron 326: 0.3866361975669861\n",
      "Neuron 431: 0.38690313696861267\n",
      "Neuron 317: 0.3873938024044037\n",
      "Neuron 402: 0.3880709707736969\n",
      "Neuron 103: 0.38808131217956543\n",
      "Neuron 238: 0.3888736963272095\n",
      "Neuron 400: 0.389128178358078\n",
      "Neuron 154: 0.3896784782409668\n",
      "Neuron 278: 0.3898181915283203\n",
      "Neuron 360: 0.390185683965683\n",
      "Neuron 359: 0.390264093875885\n",
      "Neuron 475: 0.3913804590702057\n",
      "Neuron 350: 0.3918182849884033\n",
      "Neuron 372: 0.3923821747303009\n",
      "Neuron 386: 0.3937745988368988\n",
      "Neuron 300: 0.3939657211303711\n",
      "Neuron 430: 0.39459228515625\n",
      "Neuron 426: 0.39519503712654114\n",
      "Neuron 482: 0.3953505754470825\n",
      "Neuron 233: 0.397664874792099\n",
      "Neuron 476: 0.39814597368240356\n",
      "Neuron 392: 0.39927542209625244\n",
      "Neuron 122: 0.4006769061088562\n",
      "Neuron 205: 0.4007691740989685\n",
      "Neuron 460: 0.4032955467700958\n",
      "Neuron 450: 0.4042873978614807\n",
      "Neuron 439: 0.4044806659221649\n",
      "Neuron 118: 0.40450718998908997\n",
      "Neuron 323: 0.41085493564605713\n",
      "Neuron 74: 0.4110630750656128\n",
      "Neuron 500: 0.4121305048465729\n",
      "Neuron 100: 0.4148608446121216\n",
      "Neuron 395: 0.4161345660686493\n",
      "Neuron 511: 0.4163200557231903\n",
      "Neuron 81: 0.41707783937454224\n",
      "Neuron 324: 0.41719233989715576\n",
      "Neuron 492: 0.41763588786125183\n",
      "Neuron 179: 0.4177744686603546\n",
      "Neuron 243: 0.42175644636154175\n",
      "Neuron 170: 0.4232988655567169\n",
      "Neuron 132: 0.42443573474884033\n",
      "Neuron 116: 0.4244998097419739\n",
      "Neuron 60: 0.42517030239105225\n",
      "Neuron 263: 0.42575499415397644\n",
      "Neuron 504: 0.42693114280700684\n",
      "Neuron 438: 0.42736944556236267\n",
      "Neuron 199: 0.42850425839424133\n",
      "Neuron 144: 0.42927369475364685\n",
      "Neuron 20: 0.4303515553474426\n",
      "Neuron 174: 0.43420571088790894\n",
      "Neuron 93: 0.4362454116344452\n",
      "Neuron 134: 0.43868574500083923\n",
      "Neuron 418: 0.44064706563949585\n",
      "Neuron 186: 0.44402486085891724\n",
      "Neuron 394: 0.44517749547958374\n",
      "Neuron 349: 0.4479977488517761\n",
      "Neuron 493: 0.44874173402786255\n",
      "Neuron 159: 0.4489138722419739\n",
      "Neuron 46: 0.44942134618759155\n",
      "Neuron 254: 0.4505472779273987\n",
      "Neuron 413: 0.45445016026496887\n",
      "Neuron 344: 0.4552619159221649\n",
      "Neuron 5: 0.4553469717502594\n",
      "Neuron 481: 0.4553758203983307\n",
      "Neuron 119: 0.45690053701400757\n",
      "Neuron 177: 0.45765024423599243\n",
      "Neuron 321: 0.4639391005039215\n",
      "Neuron 373: 0.46506568789482117\n",
      "Neuron 369: 0.47145459055900574\n",
      "Neuron 362: 0.4721173346042633\n",
      "Neuron 502: 0.4783186912536621\n",
      "Neuron 66: 0.47905316948890686\n",
      "Neuron 201: 0.4793380796909332\n",
      "Neuron 102: 0.48547065258026123\n",
      "Neuron 309: 0.5046746134757996\n",
      "Neuron 416: 0.505813717842102\n",
      "Neuron 141: 0.5066510438919067\n",
      "Neuron 1: 0.5277276635169983\n",
      "Neuron 45: 0.5354892611503601\n",
      "Neuron 409: 0.5502686500549316\n",
      "Neuron 459: 0.5531987547874451\n",
      "Neuron 193: 0.5629692673683167\n",
      "Neuron 80: 0.5778976082801819\n",
      "Neuron 494: 0.5890339612960815\n",
      "Neuron 456: 0.6035900115966797\n",
      "Neuron 365: 0.6053479313850403\n"
     ]
    }
   ],
   "source": [
    "# #检测权重是否被修改\n",
    "# last_conv_layer = model.layers[-12]\n",
    "# last_conv_layer_model = tf.keras.models.Model(model.inputs, last_conv_layer.output)\n",
    "# conv_outputs = last_conv_layer_model.predict(test_dataset)\n",
    "# # conv_outputs\n",
    "# average_activations = tf.reduce_mean(conv_outputs, axis=(0,1,2)) # 计算每个神经元在整个测试数据集上的平均激活值\n",
    "# sorted_indices = tf.argsort(average_activations, direction='ASCENDING') # 对平均激活值进行排序\n",
    "# for i in range(len(sorted_indices)): #打印排序后的神经元及其对应的平均激活值\n",
    "#     print(f\"Neuron {sorted_indices[i]}: {average_activations[sorted_indices[i]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "071d0d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# #检测权重是否已经被修改\n",
    "# last_conv_layer = model.layers[-12]\n",
    "# last_conv_layer_model = tf.keras.models.Model(model.inputs, last_conv_layer.output)\n",
    "# conv_outputs = last_conv_layer_model.predict(test_dataset)\n",
    "# average_output = tf.reduce_mean(conv_outputs, axis=0)\n",
    "# average_output\n",
    "# plt.imshow(average_output[:,:,236], cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12b62df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=0, accuracy=0.8898000121116638\n",
      "K: 0\n",
      "k=1, accuracy=0.8898000121116638\n",
      "K: 1\n",
      "k=2, accuracy=0.8898000121116638\n",
      "K: 2\n",
      "k=3, accuracy=0.8898000121116638\n",
      "K: 3\n",
      "k=4, accuracy=0.8898000121116638\n",
      "K: 4\n",
      "k=5, accuracy=0.8898000121116638\n",
      "K: 5\n",
      "k=6, accuracy=0.8898000121116638\n",
      "K: 6\n",
      "k=7, accuracy=0.8895999789237976\n",
      "K: 7\n",
      "k=8, accuracy=0.8895999789237976\n",
      "K: 8\n",
      "k=9, accuracy=0.8895999789237976\n",
      "K: 9\n",
      "k=10, accuracy=0.8895000219345093\n",
      "K: 10\n",
      "k=11, accuracy=0.8895999789237976\n",
      "K: 11\n",
      "k=12, accuracy=0.8895000219345093\n",
      "K: 12\n",
      "k=13, accuracy=0.8898000121116638\n",
      "K: 13\n",
      "k=14, accuracy=0.8898000121116638\n",
      "K: 14\n",
      "k=15, accuracy=0.8895999789237976\n",
      "K: 15\n",
      "k=16, accuracy=0.8895999789237976\n",
      "K: 16\n",
      "k=17, accuracy=0.8894000053405762\n",
      "K: 17\n",
      "k=18, accuracy=0.8896999955177307\n",
      "K: 18\n",
      "k=19, accuracy=0.8895000219345093\n",
      "K: 19\n",
      "k=20, accuracy=0.8896999955177307\n",
      "K: 20\n",
      "k=21, accuracy=0.8902000188827515\n",
      "K: 21\n",
      "k=22, accuracy=0.8899999856948853\n",
      "K: 22\n",
      "k=23, accuracy=0.8899999856948853\n",
      "K: 23\n",
      "k=24, accuracy=0.8902999758720398\n",
      "K: 24\n",
      "k=25, accuracy=0.8899999856948853\n",
      "K: 25\n",
      "k=26, accuracy=0.8898000121116638\n",
      "K: 26\n",
      "k=27, accuracy=0.8899000287055969\n",
      "K: 27\n",
      "k=28, accuracy=0.8898000121116638\n",
      "K: 28\n",
      "k=29, accuracy=0.8895999789237976\n",
      "K: 29\n",
      "k=30, accuracy=0.8895999789237976\n",
      "K: 30\n",
      "k=31, accuracy=0.8895999789237976\n",
      "K: 31\n",
      "k=32, accuracy=0.8895999789237976\n",
      "K: 32\n",
      "k=33, accuracy=0.8898000121116638\n",
      "K: 33\n",
      "k=34, accuracy=0.8896999955177307\n",
      "K: 34\n",
      "k=35, accuracy=0.8896999955177307\n",
      "K: 35\n",
      "k=36, accuracy=0.8896999955177307\n",
      "K: 36\n",
      "k=37, accuracy=0.8899000287055969\n",
      "K: 37\n",
      "k=38, accuracy=0.8895000219345093\n",
      "K: 38\n",
      "k=39, accuracy=0.8894000053405762\n",
      "K: 39\n",
      "k=40, accuracy=0.88919997215271\n",
      "K: 40\n",
      "k=41, accuracy=0.8891000151634216\n",
      "K: 41\n",
      "k=42, accuracy=0.8895000219345093\n",
      "K: 42\n",
      "k=43, accuracy=0.8895999789237976\n",
      "K: 43\n",
      "k=44, accuracy=0.8898000121116638\n",
      "K: 44\n",
      "k=45, accuracy=0.8895999789237976\n",
      "K: 45\n",
      "k=46, accuracy=0.8896999955177307\n",
      "K: 46\n",
      "k=47, accuracy=0.8896999955177307\n",
      "K: 47\n",
      "k=48, accuracy=0.8899999856948853\n",
      "K: 48\n",
      "k=49, accuracy=0.8896999955177307\n",
      "K: 49\n",
      "k=50, accuracy=0.8895000219345093\n",
      "K: 50\n",
      "k=51, accuracy=0.8899000287055969\n",
      "K: 51\n",
      "k=52, accuracy=0.8898000121116638\n",
      "K: 52\n",
      "k=53, accuracy=0.8899999856948853\n",
      "K: 53\n",
      "k=54, accuracy=0.8899999856948853\n",
      "K: 54\n",
      "k=55, accuracy=0.8899000287055969\n",
      "K: 55\n",
      "k=56, accuracy=0.8902000188827515\n",
      "K: 56\n",
      "k=57, accuracy=0.8901000022888184\n",
      "K: 57\n",
      "k=58, accuracy=0.8899999856948853\n",
      "K: 58\n",
      "k=59, accuracy=0.8899999856948853\n",
      "K: 59\n",
      "k=60, accuracy=0.8899999856948853\n",
      "K: 60\n",
      "k=61, accuracy=0.8899000287055969\n",
      "K: 61\n",
      "k=62, accuracy=0.8902999758720398\n",
      "K: 62\n",
      "k=63, accuracy=0.8902999758720398\n",
      "K: 63\n",
      "k=64, accuracy=0.8903999924659729\n",
      "K: 64\n",
      "k=65, accuracy=0.8901000022888184\n",
      "K: 65\n",
      "k=66, accuracy=0.8901000022888184\n",
      "K: 66\n",
      "k=67, accuracy=0.8899000287055969\n",
      "K: 67\n",
      "k=68, accuracy=0.8896999955177307\n",
      "K: 68\n",
      "k=69, accuracy=0.8895000219345093\n",
      "K: 69\n",
      "k=70, accuracy=0.8896999955177307\n",
      "K: 70\n",
      "k=71, accuracy=0.8895999789237976\n",
      "K: 71\n",
      "k=72, accuracy=0.8895000219345093\n",
      "K: 72\n",
      "k=73, accuracy=0.8894000053405762\n",
      "K: 73\n",
      "k=74, accuracy=0.8895999789237976\n",
      "K: 74\n",
      "k=75, accuracy=0.8895999789237976\n",
      "K: 75\n",
      "k=76, accuracy=0.8896999955177307\n",
      "K: 76\n",
      "k=77, accuracy=0.8892999887466431\n",
      "K: 77\n",
      "k=78, accuracy=0.8892999887466431\n",
      "K: 78\n",
      "k=79, accuracy=0.8895000219345093\n",
      "K: 79\n",
      "k=80, accuracy=0.8895000219345093\n",
      "K: 80\n",
      "k=81, accuracy=0.8891000151634216\n",
      "K: 81\n",
      "k=82, accuracy=0.8891000151634216\n",
      "K: 82\n",
      "k=83, accuracy=0.8889999985694885\n",
      "K: 83\n",
      "k=84, accuracy=0.8889999985694885\n",
      "K: 84\n",
      "k=85, accuracy=0.8891000151634216\n",
      "K: 85\n",
      "k=86, accuracy=0.8889999985694885\n",
      "K: 86\n",
      "k=87, accuracy=0.88919997215271\n",
      "K: 87\n",
      "k=88, accuracy=0.88919997215271\n",
      "K: 88\n",
      "k=89, accuracy=0.8892999887466431\n",
      "K: 89\n",
      "k=90, accuracy=0.8891000151634216\n",
      "K: 90\n",
      "k=91, accuracy=0.8888999819755554\n",
      "K: 91\n",
      "k=92, accuracy=0.8885999917984009\n",
      "K: 92\n",
      "k=93, accuracy=0.8885999917984009\n",
      "K: 93\n",
      "k=94, accuracy=0.8885999917984009\n",
      "K: 94\n",
      "k=95, accuracy=0.8885999917984009\n",
      "K: 95\n",
      "k=96, accuracy=0.8884000182151794\n",
      "K: 96\n",
      "k=97, accuracy=0.8884000182151794\n",
      "K: 97\n",
      "k=98, accuracy=0.888700008392334\n",
      "K: 98\n",
      "k=99, accuracy=0.8888000249862671\n",
      "K: 99\n",
      "k=100, accuracy=0.8888999819755554\n",
      "K: 100\n",
      "k=101, accuracy=0.888700008392334\n",
      "K: 101\n",
      "k=102, accuracy=0.888700008392334\n",
      "K: 102\n",
      "k=103, accuracy=0.8884999752044678\n",
      "K: 103\n",
      "k=104, accuracy=0.8884000182151794\n",
      "K: 104\n",
      "k=105, accuracy=0.8881000280380249\n",
      "K: 105\n",
      "k=106, accuracy=0.8880000114440918\n",
      "K: 106\n",
      "k=107, accuracy=0.8883000016212463\n",
      "K: 107\n",
      "k=108, accuracy=0.8881000280380249\n",
      "K: 108\n",
      "k=109, accuracy=0.8884000182151794\n",
      "K: 109\n",
      "k=110, accuracy=0.8883000016212463\n",
      "K: 110\n",
      "k=111, accuracy=0.8881000280380249\n",
      "K: 111\n",
      "k=112, accuracy=0.8881000280380249\n",
      "K: 112\n",
      "k=113, accuracy=0.8880000114440918\n",
      "K: 113\n",
      "k=114, accuracy=0.8883000016212463\n",
      "K: 114\n",
      "k=115, accuracy=0.8881999850273132\n",
      "K: 115\n",
      "k=116, accuracy=0.8881999850273132\n",
      "K: 116\n",
      "k=117, accuracy=0.8877999782562256\n",
      "K: 117\n",
      "k=118, accuracy=0.8871999979019165\n",
      "K: 118\n",
      "k=119, accuracy=0.8870999813079834\n",
      "K: 119\n",
      "k=120, accuracy=0.8871999979019165\n",
      "K: 120\n",
      "k=121, accuracy=0.8870999813079834\n",
      "K: 121\n",
      "k=122, accuracy=0.8867999911308289\n",
      "K: 122\n",
      "k=123, accuracy=0.8865000009536743\n",
      "K: 123\n",
      "k=124, accuracy=0.8863000273704529\n",
      "K: 124\n",
      "k=125, accuracy=0.8860999941825867\n",
      "K: 125\n",
      "k=126, accuracy=0.8862000107765198\n",
      "K: 126\n",
      "k=127, accuracy=0.8862000107765198\n",
      "K: 127\n",
      "k=128, accuracy=0.8862000107765198\n",
      "K: 128\n",
      "k=129, accuracy=0.8865000009536743\n",
      "K: 129\n",
      "k=130, accuracy=0.8863999843597412\n",
      "K: 130\n",
      "k=131, accuracy=0.8863999843597412\n",
      "K: 131\n",
      "k=132, accuracy=0.8865000009536743\n",
      "K: 132\n",
      "k=133, accuracy=0.8863999843597412\n",
      "K: 133\n",
      "k=134, accuracy=0.8865000009536743\n",
      "K: 134\n",
      "k=135, accuracy=0.8863999843597412\n",
      "K: 135\n",
      "k=136, accuracy=0.8862000107765198\n",
      "K: 136\n",
      "k=137, accuracy=0.8862000107765198\n",
      "K: 137\n",
      "k=138, accuracy=0.8859999775886536\n",
      "K: 138\n",
      "k=139, accuracy=0.8855999708175659\n",
      "K: 139\n",
      "k=140, accuracy=0.885699987411499\n",
      "K: 140\n",
      "k=141, accuracy=0.8855000138282776\n",
      "K: 141\n",
      "k=142, accuracy=0.8853999972343445\n",
      "K: 142\n",
      "k=143, accuracy=0.8855000138282776\n",
      "K: 143\n",
      "k=144, accuracy=0.8851000070571899\n",
      "K: 144\n",
      "k=145, accuracy=0.8852999806404114\n",
      "K: 145\n",
      "k=146, accuracy=0.8851000070571899\n",
      "K: 146\n",
      "k=147, accuracy=0.8842999935150146\n",
      "K: 147\n",
      "k=148, accuracy=0.8847000002861023\n",
      "K: 148\n",
      "k=149, accuracy=0.8841999769210815\n",
      "K: 149\n",
      "k=150, accuracy=0.8840000033378601\n",
      "K: 150\n",
      "k=151, accuracy=0.8837000131607056\n",
      "K: 151\n",
      "k=152, accuracy=0.8833000063896179\n",
      "K: 152\n",
      "k=153, accuracy=0.8833000063896179\n",
      "K: 153\n",
      "k=154, accuracy=0.883400022983551\n",
      "K: 154\n",
      "k=155, accuracy=0.8835999965667725\n",
      "K: 155\n",
      "k=156, accuracy=0.8833000063896179\n",
      "K: 156\n",
      "k=157, accuracy=0.8834999799728394\n",
      "K: 157\n",
      "k=158, accuracy=0.8831999897956848\n",
      "K: 158\n",
      "k=159, accuracy=0.8830000162124634\n",
      "K: 159\n",
      "k=160, accuracy=0.8827999830245972\n",
      "K: 160\n",
      "k=161, accuracy=0.8827999830245972\n",
      "K: 161\n",
      "k=162, accuracy=0.8812000155448914\n",
      "K: 162\n",
      "k=163, accuracy=0.8802000284194946\n",
      "K: 163\n",
      "k=164, accuracy=0.8794000148773193\n",
      "K: 164\n",
      "k=165, accuracy=0.8791999816894531\n",
      "K: 165\n",
      "k=166, accuracy=0.879800021648407\n",
      "K: 166\n",
      "k=167, accuracy=0.8791000247001648\n",
      "K: 167\n",
      "k=168, accuracy=0.8790000081062317\n",
      "K: 168\n",
      "k=169, accuracy=0.8787000179290771\n",
      "K: 169\n",
      "k=170, accuracy=0.8787000179290771\n",
      "K: 170\n",
      "k=171, accuracy=0.8776999711990356\n",
      "K: 171\n",
      "k=172, accuracy=0.878000020980835\n",
      "K: 172\n",
      "k=173, accuracy=0.8777999877929688\n",
      "K: 173\n",
      "k=174, accuracy=0.8748999834060669\n",
      "K: 174\n",
      "k=175, accuracy=0.8748999834060669\n",
      "K: 175\n",
      "k=176, accuracy=0.8733999729156494\n",
      "K: 176\n",
      "k=177, accuracy=0.8727999925613403\n",
      "K: 177\n",
      "k=178, accuracy=0.8726999759674072\n",
      "K: 178\n",
      "k=179, accuracy=0.8722000122070312\n",
      "K: 179\n",
      "k=180, accuracy=0.8720999956130981\n",
      "K: 180\n",
      "k=181, accuracy=0.8718000054359436\n",
      "K: 181\n",
      "k=182, accuracy=0.871999979019165\n",
      "K: 182\n",
      "k=183, accuracy=0.8711000084877014\n",
      "K: 183\n",
      "k=184, accuracy=0.8712000250816345\n",
      "K: 184\n",
      "k=185, accuracy=0.8712999820709229\n",
      "K: 185\n",
      "k=186, accuracy=0.8701000213623047\n",
      "K: 186\n",
      "k=187, accuracy=0.8691999912261963\n",
      "K: 187\n",
      "k=188, accuracy=0.8666999936103821\n",
      "K: 188\n",
      "k=189, accuracy=0.8661999702453613\n",
      "K: 189\n",
      "k=190, accuracy=0.8608999848365784\n",
      "K: 190\n",
      "k=191, accuracy=0.8589000105857849\n",
      "K: 191\n",
      "k=192, accuracy=0.859000027179718\n",
      "K: 192\n",
      "k=193, accuracy=0.8604999780654907\n",
      "K: 193\n",
      "k=194, accuracy=0.8601999878883362\n",
      "K: 194\n",
      "k=195, accuracy=0.859000027179718\n",
      "K: 195\n",
      "k=196, accuracy=0.8590999841690063\n",
      "K: 196\n",
      "k=197, accuracy=0.852400004863739\n",
      "K: 197\n",
      "k=198, accuracy=0.8526999950408936\n",
      "K: 198\n",
      "k=199, accuracy=0.8529000282287598\n",
      "K: 199\n",
      "k=200, accuracy=0.8511000275611877\n",
      "K: 200\n",
      "k=201, accuracy=0.8510000109672546\n",
      "K: 201\n",
      "k=202, accuracy=0.8499000072479248\n",
      "K: 202\n",
      "k=203, accuracy=0.8457000255584717\n",
      "K: 203\n",
      "k=204, accuracy=0.832099974155426\n",
      "K: 204\n",
      "k=205, accuracy=0.8310999870300293\n",
      "K: 205\n",
      "k=206, accuracy=0.830299973487854\n",
      "K: 206\n",
      "k=207, accuracy=0.8269000053405762\n",
      "K: 207\n",
      "k=208, accuracy=0.8267999887466431\n",
      "K: 208\n",
      "k=209, accuracy=0.8241999745368958\n",
      "K: 209\n",
      "k=210, accuracy=0.8291000127792358\n",
      "K: 210\n",
      "k=211, accuracy=0.8287000060081482\n",
      "K: 211\n",
      "k=212, accuracy=0.8291000127792358\n",
      "K: 212\n",
      "k=213, accuracy=0.8296999931335449\n",
      "K: 213\n",
      "k=214, accuracy=0.8374000191688538\n",
      "K: 214\n",
      "k=215, accuracy=0.8353999853134155\n",
      "K: 215\n",
      "k=216, accuracy=0.8273000121116638\n",
      "K: 216\n",
      "k=217, accuracy=0.8263000249862671\n",
      "K: 217\n",
      "k=218, accuracy=0.828499972820282\n",
      "K: 218\n",
      "k=219, accuracy=0.8234999775886536\n",
      "K: 219\n",
      "k=220, accuracy=0.8233000040054321\n",
      "K: 220\n",
      "k=221, accuracy=0.8230000138282776\n",
      "K: 221\n",
      "k=222, accuracy=0.8256000280380249\n",
      "K: 222\n",
      "k=223, accuracy=0.8295999765396118\n",
      "K: 223\n",
      "k=224, accuracy=0.8317000269889832\n",
      "K: 224\n",
      "k=225, accuracy=0.817300021648407\n",
      "K: 225\n",
      "k=226, accuracy=0.8353999853134155\n",
      "K: 226\n",
      "k=227, accuracy=0.8206999897956848\n",
      "K: 227\n",
      "k=228, accuracy=0.8230999708175659\n",
      "K: 228\n",
      "k=229, accuracy=0.8233000040054321\n",
      "K: 229\n",
      "k=230, accuracy=0.8105999827384949\n",
      "K: 230\n",
      "k=231, accuracy=0.8217999935150146\n",
      "K: 231\n",
      "k=232, accuracy=0.8198000192642212\n",
      "K: 232\n",
      "k=233, accuracy=0.8194000124931335\n",
      "K: 233\n",
      "k=234, accuracy=0.8210999965667725\n",
      "K: 234\n",
      "k=235, accuracy=0.8159999847412109\n",
      "K: 235\n",
      "k=236, accuracy=0.8169000148773193\n",
      "K: 236\n",
      "k=237, accuracy=0.8192999958992004\n",
      "K: 237\n",
      "k=238, accuracy=0.8118000030517578\n",
      "K: 238\n",
      "k=239, accuracy=0.8098999857902527\n",
      "K: 239\n",
      "k=240, accuracy=0.8127999901771545\n",
      "K: 240\n",
      "k=241, accuracy=0.8122000098228455\n",
      "K: 241\n",
      "k=242, accuracy=0.7997999787330627\n",
      "K: 242\n",
      "k=243, accuracy=0.8004999756813049\n",
      "K: 243\n",
      "k=244, accuracy=0.800599992275238\n",
      "K: 244\n",
      "k=245, accuracy=0.7949000000953674\n",
      "K: 245\n",
      "k=246, accuracy=0.7929999828338623\n",
      "K: 246\n",
      "k=247, accuracy=0.79339998960495\n",
      "K: 247\n",
      "k=248, accuracy=0.7936000227928162\n",
      "K: 248\n",
      "k=249, accuracy=0.7922999858856201\n",
      "K: 249\n",
      "k=250, accuracy=0.7925999760627747\n",
      "K: 250\n",
      "k=251, accuracy=0.7997000217437744\n",
      "K: 251\n",
      "k=252, accuracy=0.8001999855041504\n",
      "K: 252\n",
      "k=253, accuracy=0.7975999712944031\n",
      "K: 253\n",
      "k=254, accuracy=0.796999990940094\n",
      "K: 254\n",
      "k=255, accuracy=0.7979000210762024\n",
      "K: 255\n",
      "k=256, accuracy=0.7968000173568726\n",
      "K: 256\n",
      "k=257, accuracy=0.7914000153541565\n",
      "K: 257\n",
      "k=258, accuracy=0.7890999913215637\n",
      "K: 258\n",
      "k=259, accuracy=0.7889000177383423\n",
      "K: 259\n",
      "k=260, accuracy=0.7878999710083008\n",
      "K: 260\n",
      "k=261, accuracy=0.7878000140190125\n",
      "K: 261\n",
      "k=262, accuracy=0.7864999771118164\n",
      "K: 262\n",
      "k=263, accuracy=0.7864000201225281\n",
      "K: 263\n",
      "k=264, accuracy=0.7858999967575073\n",
      "K: 264\n",
      "k=265, accuracy=0.7856000065803528\n",
      "K: 265\n",
      "k=266, accuracy=0.7857999801635742\n",
      "K: 266\n",
      "k=267, accuracy=0.7839999794960022\n",
      "K: 267\n",
      "k=268, accuracy=0.7839999794960022\n",
      "K: 268\n",
      "k=269, accuracy=0.7843000292778015\n",
      "K: 269\n",
      "k=270, accuracy=0.7839999794960022\n",
      "K: 270\n",
      "k=271, accuracy=0.7833999991416931\n",
      "K: 271\n",
      "k=272, accuracy=0.7835000157356262\n",
      "K: 272\n",
      "k=273, accuracy=0.7835999727249146\n",
      "K: 273\n",
      "k=274, accuracy=0.7828999757766724\n",
      "K: 274\n",
      "k=275, accuracy=0.7831000089645386\n",
      "K: 275\n",
      "k=276, accuracy=0.7840999960899353\n",
      "K: 276\n",
      "k=277, accuracy=0.7851999998092651\n",
      "K: 277\n",
      "k=278, accuracy=0.7858999967575073\n",
      "K: 278\n",
      "k=279, accuracy=0.7843999862670898\n",
      "K: 279\n",
      "k=280, accuracy=0.7831000089645386\n",
      "K: 280\n",
      "k=281, accuracy=0.7803000211715698\n",
      "K: 281\n",
      "k=282, accuracy=0.779699981212616\n",
      "K: 282\n",
      "k=283, accuracy=0.7795000076293945\n",
      "K: 283\n",
      "k=284, accuracy=0.7802000045776367\n",
      "K: 284\n",
      "k=285, accuracy=0.7795000076293945\n",
      "K: 285\n",
      "k=286, accuracy=0.7796000242233276\n",
      "K: 286\n",
      "k=287, accuracy=0.7767000198364258\n",
      "K: 287\n",
      "k=288, accuracy=0.7766000032424927\n",
      "K: 288\n",
      "k=289, accuracy=0.7774999737739563\n",
      "K: 289\n",
      "k=290, accuracy=0.7774999737739563\n",
      "K: 290\n",
      "k=291, accuracy=0.7763000130653381\n",
      "K: 291\n",
      "k=292, accuracy=0.775600016117096\n",
      "K: 292\n",
      "k=293, accuracy=0.7750999927520752\n",
      "K: 293\n",
      "k=294, accuracy=0.7748000025749207\n",
      "K: 294\n",
      "k=295, accuracy=0.7752000093460083\n",
      "K: 295\n",
      "k=296, accuracy=0.7754999995231628\n",
      "K: 296\n",
      "k=297, accuracy=0.7749999761581421\n",
      "K: 297\n",
      "k=298, accuracy=0.7768999934196472\n",
      "K: 298\n",
      "k=299, accuracy=0.7767000198364258\n",
      "K: 299\n",
      "k=300, accuracy=0.774399995803833\n",
      "K: 300\n",
      "k=301, accuracy=0.7767999768257141\n",
      "K: 301\n",
      "k=302, accuracy=0.775600016117096\n",
      "K: 302\n",
      "k=303, accuracy=0.7712000012397766\n",
      "K: 303\n",
      "k=304, accuracy=0.7709000110626221\n",
      "K: 304\n",
      "k=305, accuracy=0.7713000178337097\n",
      "K: 305\n",
      "k=306, accuracy=0.7717000246047974\n",
      "K: 306\n",
      "k=307, accuracy=0.7616000175476074\n",
      "K: 307\n",
      "k=308, accuracy=0.765500009059906\n",
      "K: 308\n",
      "k=309, accuracy=0.7578999996185303\n",
      "K: 309\n",
      "k=310, accuracy=0.7562000155448914\n",
      "K: 310\n",
      "k=311, accuracy=0.7555000185966492\n",
      "K: 311\n",
      "k=312, accuracy=0.7551000118255615\n",
      "K: 312\n",
      "k=313, accuracy=0.7547000050544739\n",
      "K: 313\n",
      "k=314, accuracy=0.7501999735832214\n",
      "K: 314\n",
      "k=315, accuracy=0.7508999705314636\n",
      "K: 315\n",
      "k=316, accuracy=0.7501000165939331\n",
      "K: 316\n",
      "k=317, accuracy=0.7476999759674072\n",
      "K: 317\n",
      "k=318, accuracy=0.7490000128746033\n",
      "K: 318\n",
      "k=319, accuracy=0.7470999956130981\n",
      "K: 319\n",
      "k=320, accuracy=0.7441999912261963\n",
      "K: 320\n",
      "k=321, accuracy=0.737500011920929\n",
      "K: 321\n",
      "k=322, accuracy=0.7383000254631042\n",
      "K: 322\n",
      "k=323, accuracy=0.7409999966621399\n",
      "K: 323\n",
      "k=324, accuracy=0.7365000247955322\n",
      "K: 324\n",
      "k=325, accuracy=0.7358999848365784\n",
      "K: 325\n",
      "k=326, accuracy=0.7246000170707703\n",
      "K: 326\n",
      "k=327, accuracy=0.7261999845504761\n",
      "K: 327\n",
      "k=328, accuracy=0.7265999913215637\n",
      "K: 328\n",
      "k=329, accuracy=0.7253000140190125\n",
      "K: 329\n",
      "k=330, accuracy=0.7283999919891357\n",
      "K: 330\n",
      "k=331, accuracy=0.7261000275611877\n",
      "K: 331\n",
      "k=332, accuracy=0.7235000133514404\n",
      "K: 332\n",
      "k=333, accuracy=0.7026000022888184\n",
      "K: 333\n",
      "k=334, accuracy=0.7107999920845032\n",
      "K: 334\n",
      "k=335, accuracy=0.7142000198364258\n",
      "K: 335\n",
      "k=336, accuracy=0.717199981212616\n",
      "K: 336\n",
      "k=337, accuracy=0.7200999855995178\n",
      "K: 337\n",
      "k=338, accuracy=0.7224000096321106\n",
      "K: 338\n",
      "k=339, accuracy=0.7235000133514404\n",
      "K: 339\n",
      "k=340, accuracy=0.7272999882698059\n",
      "K: 340\n",
      "k=341, accuracy=0.7217000126838684\n",
      "K: 341\n",
      "k=342, accuracy=0.7160000205039978\n",
      "K: 342\n",
      "k=343, accuracy=0.7163000106811523\n",
      "K: 343\n",
      "k=344, accuracy=0.7056999802589417\n",
      "K: 344\n",
      "k=345, accuracy=0.703499972820282\n",
      "K: 345\n",
      "k=346, accuracy=0.7038000226020813\n",
      "K: 346\n",
      "k=347, accuracy=0.6811000108718872\n",
      "K: 347\n",
      "k=348, accuracy=0.6812000274658203\n",
      "K: 348\n",
      "k=349, accuracy=0.6793000102043152\n",
      "K: 349\n",
      "k=350, accuracy=0.6796000003814697\n",
      "K: 350\n",
      "k=351, accuracy=0.6818000078201294\n",
      "K: 351\n",
      "k=352, accuracy=0.6804999709129333\n",
      "K: 352\n",
      "k=353, accuracy=0.6868000030517578\n",
      "K: 353\n",
      "k=354, accuracy=0.6863999962806702\n",
      "K: 354\n",
      "k=355, accuracy=0.6801999807357788\n",
      "K: 355\n",
      "k=356, accuracy=0.685699999332428\n",
      "K: 356\n",
      "k=357, accuracy=0.6901999711990356\n",
      "K: 357\n",
      "k=358, accuracy=0.6791999936103821\n",
      "K: 358\n",
      "k=359, accuracy=0.6783000230789185\n",
      "K: 359\n",
      "k=360, accuracy=0.6861000061035156\n",
      "K: 360\n",
      "k=361, accuracy=0.6959999799728394\n",
      "K: 361\n",
      "k=362, accuracy=0.6934999823570251\n",
      "K: 362\n",
      "k=363, accuracy=0.6915000081062317\n",
      "K: 363\n",
      "k=364, accuracy=0.6898999810218811\n",
      "K: 364\n",
      "k=365, accuracy=0.6894000172615051\n",
      "K: 365\n",
      "k=366, accuracy=0.6722999811172485\n",
      "K: 366\n",
      "k=367, accuracy=0.6682000160217285\n",
      "K: 367\n",
      "k=368, accuracy=0.6675000190734863\n",
      "K: 368\n",
      "k=369, accuracy=0.6686000227928162\n",
      "K: 369\n",
      "k=370, accuracy=0.6650999784469604\n",
      "K: 370\n",
      "k=371, accuracy=0.6625999808311462\n",
      "K: 371\n",
      "k=372, accuracy=0.6437000036239624\n",
      "K: 372\n",
      "k=373, accuracy=0.6395000219345093\n",
      "K: 373\n",
      "k=374, accuracy=0.6333000063896179\n",
      "K: 374\n",
      "k=375, accuracy=0.6323999762535095\n",
      "K: 375\n",
      "k=376, accuracy=0.6291999816894531\n",
      "K: 376\n",
      "k=377, accuracy=0.6227999925613403\n",
      "K: 377\n",
      "k=378, accuracy=0.6237999796867371\n",
      "K: 378\n",
      "k=379, accuracy=0.6255000233650208\n",
      "K: 379\n",
      "k=380, accuracy=0.6349999904632568\n",
      "K: 380\n",
      "k=381, accuracy=0.6288999915122986\n",
      "K: 381\n",
      "k=382, accuracy=0.6223000288009644\n",
      "K: 382\n",
      "k=383, accuracy=0.6334999799728394\n",
      "K: 383\n",
      "k=384, accuracy=0.6266000270843506\n",
      "K: 384\n",
      "k=385, accuracy=0.6298999786376953\n",
      "K: 385\n",
      "k=386, accuracy=0.6212999820709229\n",
      "K: 386\n",
      "k=387, accuracy=0.6215999722480774\n",
      "K: 387\n",
      "k=388, accuracy=0.6309999823570251\n",
      "K: 388\n",
      "k=389, accuracy=0.6341000199317932\n",
      "K: 389\n",
      "k=390, accuracy=0.6353999972343445\n",
      "K: 390\n",
      "k=391, accuracy=0.6367999911308289\n",
      "K: 391\n",
      "k=392, accuracy=0.6383000016212463\n",
      "K: 392\n",
      "k=393, accuracy=0.6376000046730042\n",
      "K: 393\n",
      "k=394, accuracy=0.6351000070571899\n",
      "K: 394\n",
      "k=395, accuracy=0.6365000009536743\n",
      "K: 395\n",
      "k=396, accuracy=0.635699987411499\n",
      "K: 396\n",
      "k=397, accuracy=0.6225000023841858\n",
      "K: 397\n",
      "k=398, accuracy=0.6223999857902527\n",
      "K: 398\n",
      "k=399, accuracy=0.6172000169754028\n",
      "K: 399\n",
      "k=400, accuracy=0.6151000261306763\n",
      "K: 400\n",
      "k=401, accuracy=0.6086000204086304\n",
      "K: 401\n",
      "k=402, accuracy=0.6072999835014343\n",
      "K: 402\n",
      "k=403, accuracy=0.6047999858856201\n",
      "K: 403\n",
      "k=404, accuracy=0.5968999862670898\n",
      "K: 404\n",
      "k=405, accuracy=0.5957000255584717\n",
      "K: 405\n",
      "k=406, accuracy=0.5963000059127808\n",
      "K: 406\n",
      "k=407, accuracy=0.5968000292778015\n",
      "K: 407\n",
      "k=408, accuracy=0.597599983215332\n",
      "K: 408\n",
      "k=409, accuracy=0.5932999849319458\n",
      "K: 409\n",
      "k=410, accuracy=0.5819000005722046\n",
      "K: 410\n",
      "k=411, accuracy=0.5813000202178955\n",
      "K: 411\n",
      "k=412, accuracy=0.5799000263214111\n",
      "K: 412\n",
      "k=413, accuracy=0.5841000080108643\n",
      "K: 413\n",
      "k=414, accuracy=0.5791000127792358\n",
      "K: 414\n",
      "k=415, accuracy=0.5806999802589417\n",
      "K: 415\n",
      "k=416, accuracy=0.5773000121116638\n",
      "K: 416\n",
      "k=417, accuracy=0.572700023651123\n",
      "K: 417\n",
      "k=418, accuracy=0.5712000131607056\n",
      "K: 418\n",
      "k=419, accuracy=0.5699999928474426\n",
      "K: 419\n",
      "k=420, accuracy=0.5679000020027161\n",
      "K: 420\n",
      "k=421, accuracy=0.5674999952316284\n",
      "K: 421\n",
      "k=422, accuracy=0.5674999952316284\n",
      "K: 422\n",
      "k=423, accuracy=0.5587000250816345\n",
      "K: 423\n",
      "k=424, accuracy=0.5583000183105469\n",
      "K: 424\n",
      "k=425, accuracy=0.5464000105857849\n",
      "K: 425\n",
      "k=426, accuracy=0.5471000075340271\n",
      "K: 426\n",
      "k=427, accuracy=0.5349000096321106\n",
      "K: 427\n",
      "k=428, accuracy=0.5329999923706055\n",
      "K: 428\n",
      "k=429, accuracy=0.529699981212616\n",
      "K: 429\n",
      "k=430, accuracy=0.5238999724388123\n",
      "K: 430\n",
      "k=431, accuracy=0.5177000164985657\n",
      "K: 431\n",
      "k=432, accuracy=0.5156999826431274\n",
      "K: 432\n",
      "k=433, accuracy=0.5116000175476074\n",
      "K: 433\n",
      "k=434, accuracy=0.5070000290870667\n",
      "K: 434\n",
      "k=435, accuracy=0.4977000057697296\n",
      "K: 435\n",
      "k=436, accuracy=0.4909999966621399\n",
      "K: 436\n",
      "k=437, accuracy=0.47269999980926514\n",
      "K: 437\n",
      "k=438, accuracy=0.4700999855995178\n",
      "K: 438\n",
      "k=439, accuracy=0.46799999475479126\n",
      "K: 439\n",
      "k=440, accuracy=0.4657000005245209\n",
      "K: 440\n",
      "k=441, accuracy=0.4586000144481659\n",
      "K: 441\n",
      "k=442, accuracy=0.4487999975681305\n",
      "K: 442\n",
      "k=443, accuracy=0.43209999799728394\n",
      "K: 443\n",
      "k=444, accuracy=0.41620001196861267\n",
      "K: 444\n",
      "k=445, accuracy=0.4129999876022339\n",
      "K: 445\n",
      "k=446, accuracy=0.4146000146865845\n",
      "K: 446\n",
      "k=447, accuracy=0.40709999203681946\n",
      "K: 447\n",
      "k=448, accuracy=0.4018999934196472\n",
      "K: 448\n",
      "k=449, accuracy=0.40299999713897705\n",
      "K: 449\n",
      "k=450, accuracy=0.4068000018596649\n",
      "K: 450\n",
      "k=451, accuracy=0.4072999954223633\n",
      "K: 451\n",
      "k=452, accuracy=0.3955000042915344\n",
      "K: 452\n",
      "k=453, accuracy=0.3873000144958496\n",
      "K: 453\n",
      "k=454, accuracy=0.38429999351501465\n",
      "K: 454\n",
      "k=455, accuracy=0.3767000138759613\n",
      "K: 455\n",
      "k=456, accuracy=0.37279999256134033\n",
      "K: 456\n",
      "k=457, accuracy=0.3716000020503998\n",
      "K: 457\n",
      "k=458, accuracy=0.3634999990463257\n",
      "K: 458\n",
      "k=459, accuracy=0.3553999960422516\n",
      "K: 459\n",
      "k=460, accuracy=0.3531999886035919\n",
      "K: 460\n",
      "k=461, accuracy=0.35350000858306885\n",
      "K: 461\n",
      "k=462, accuracy=0.34689998626708984\n",
      "K: 462\n",
      "k=463, accuracy=0.3440999984741211\n",
      "K: 463\n",
      "k=464, accuracy=0.3440000116825104\n",
      "K: 464\n",
      "k=465, accuracy=0.33719998598098755\n",
      "K: 465\n",
      "k=466, accuracy=0.32989999651908875\n",
      "K: 466\n",
      "k=467, accuracy=0.32359999418258667\n",
      "K: 467\n",
      "k=468, accuracy=0.310699999332428\n",
      "K: 468\n",
      "k=469, accuracy=0.28439998626708984\n",
      "K: 469\n",
      "k=470, accuracy=0.27889999747276306\n",
      "K: 470\n",
      "k=471, accuracy=0.27709999680519104\n",
      "K: 471\n",
      "k=472, accuracy=0.26660001277923584\n",
      "K: 472\n",
      "k=473, accuracy=0.2599000036716461\n",
      "K: 473\n",
      "k=474, accuracy=0.2572000026702881\n",
      "K: 474\n",
      "k=475, accuracy=0.24009999632835388\n",
      "K: 475\n",
      "k=476, accuracy=0.23499999940395355\n",
      "K: 476\n",
      "k=477, accuracy=0.22370000183582306\n",
      "K: 477\n",
      "k=478, accuracy=0.22050000727176666\n",
      "K: 478\n",
      "k=479, accuracy=0.21549999713897705\n",
      "K: 479\n",
      "k=480, accuracy=0.20970000326633453\n",
      "K: 480\n",
      "k=481, accuracy=0.20550000667572021\n",
      "K: 481\n",
      "k=482, accuracy=0.19290000200271606\n",
      "K: 482\n",
      "k=483, accuracy=0.18809999525547028\n",
      "K: 483\n",
      "k=484, accuracy=0.17190000414848328\n",
      "K: 484\n",
      "k=485, accuracy=0.17219999432563782\n",
      "K: 485\n",
      "k=486, accuracy=0.13930000364780426\n",
      "K: 486\n",
      "k=487, accuracy=0.13259999454021454\n",
      "K: 487\n",
      "k=488, accuracy=0.1354999989271164\n",
      "K: 488\n",
      "k=489, accuracy=0.133200004696846\n",
      "K: 489\n",
      "k=490, accuracy=0.1315000057220459\n",
      "K: 490\n",
      "k=491, accuracy=0.12129999697208405\n",
      "K: 491\n",
      "k=492, accuracy=0.12110000103712082\n",
      "K: 492\n",
      "k=493, accuracy=0.11330000311136246\n",
      "K: 493\n",
      "k=494, accuracy=0.11219999939203262\n",
      "K: 494\n",
      "k=495, accuracy=0.11240000277757645\n",
      "K: 495\n",
      "k=496, accuracy=0.11159999668598175\n",
      "K: 496\n",
      "k=497, accuracy=0.10989999771118164\n",
      "K: 497\n",
      "k=498, accuracy=0.10599999874830246\n",
      "K: 498\n",
      "k=499, accuracy=0.10080000013113022\n",
      "K: 499\n",
      "k=500, accuracy=0.1006999984383583\n",
      "K: 500\n",
      "k=501, accuracy=0.10000000149011612\n",
      "K: 501\n",
      "k=502, accuracy=0.10000000149011612\n",
      "K: 502\n",
      "k=503, accuracy=0.10000000149011612\n",
      "K: 503\n",
      "k=504, accuracy=0.10000000149011612\n",
      "K: 504\n",
      "k=505, accuracy=0.10000000149011612\n",
      "K: 505\n",
      "k=506, accuracy=0.10000000149011612\n",
      "K: 506\n",
      "k=507, accuracy=0.10000000149011612\n",
      "K: 507\n",
      "k=508, accuracy=0.10000000149011612\n",
      "K: 508\n",
      "k=509, accuracy=0.10000000149011612\n",
      "K: 509\n",
      "k=510, accuracy=0.10000000149011612\n",
      "K: 510\n",
      "k=511, accuracy=0.10000000149011612\n",
      "K: 511\n"
     ]
    }
   ],
   "source": [
    "accuracies = [] # 创建数组记录预测准确率变化\n",
    "# for i in range(0,5):\n",
    "for i in range(0,average_output.shape[2]):\n",
    "    K = i # 要剪枝的神经元数\n",
    "    last_conv_layer = model.layers[-12]\n",
    "    last_conv_layer_model = tf.keras.models.Model(model.inputs, last_conv_layer.output)\n",
    "    conv_outputs = last_conv_layer_model.predict(test_dataset)\n",
    "    weights, biases = last_conv_layer.get_weights()\n",
    "    average_activations = tf.reduce_mean(conv_outputs, axis=(0,1,2)) # 计算每个神经元在整个测试数据集上的平均激活值\n",
    "    sorted_indices = tf.argsort(average_activations, direction='ASCENDING') # 对平均激活值进行排序\n",
    "    for j in range(0, K):\n",
    "#         print('j:', j)\n",
    "        neuron_index = sorted_indices[j]\n",
    "        weights[:,:,:,neuron_index] = 0 # 将该神经元的权重设为0\n",
    "        biases[neuron_index] = 0 # 将该神经元的偏置设为0\n",
    "    last_conv_layer.set_weights([weights, biases]) # 更新最后一层卷积层的权重和偏置\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # 进行测试\n",
    "    _, accuracy = model.evaluate(test_dataset, verbose=0)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'k={K}, accuracy={accuracy}')\n",
    "#     sorted_indices = tf.argsort(average_activations, direction='ASCENDING') # 对平均激活值进行排序\n",
    "#     for i in range(0,10): #打印排序后的神经元及其对应的平均激活值\n",
    "#         print(f\"Neuron {sorted_indices[i]}: {average_activations[sorted_indices[i]]}\")\n",
    "    print('K:', K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d02b6eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 用于检测权重是否被修改\n",
    "# average_activations = tf.reduce_mean(conv_outputs, axis=(0,1,2)) # 计算每个神经元在整个测试数据集上的平均激活值\n",
    "# sorted_indices = tf.argsort(average_activations, direction='ASCENDING') # 对平均激活值进行排序\n",
    "# for i in range(len(sorted_indices)): #打印排序后的神经元及其对应的平均激活值\n",
    "#     print(f\"Neuron {sorted_indices[i]}: {average_activations[sorted_indices[i]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a198e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=511, accuracy=0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# 进行测试\n",
    "_, accuracy = model.evaluate(test_dataset, verbose=0)\n",
    "print(f'k={K}, accuracy={accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df217fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuron 0: 0.0\n",
      "Neuron 1: 0.0\n",
      "Neuron 2: 0.0\n",
      "Neuron 3: 0.0\n",
      "Neuron 4: 0.0\n",
      "Neuron 5: 0.0\n",
      "Neuron 6: 0.0\n",
      "Neuron 7: 0.0\n",
      "Neuron 8: 0.0\n",
      "Neuron 9: 0.0\n",
      "Neuron 10: 0.0\n",
      "Neuron 11: 0.0\n",
      "Neuron 12: 0.0\n",
      "Neuron 13: 0.0\n",
      "Neuron 14: 0.0\n",
      "Neuron 15: 0.0\n",
      "Neuron 16: 0.0\n",
      "Neuron 17: 0.0\n",
      "Neuron 18: 0.0\n",
      "Neuron 19: 0.0\n",
      "Neuron 20: 0.0\n",
      "Neuron 21: 0.0\n",
      "Neuron 22: 0.0\n",
      "Neuron 23: 0.0\n",
      "Neuron 24: 0.0\n",
      "Neuron 25: 0.0\n",
      "Neuron 26: 0.0\n",
      "Neuron 27: 0.0\n",
      "Neuron 28: 0.0\n",
      "Neuron 29: 0.0\n",
      "Neuron 30: 0.0\n",
      "Neuron 31: 0.0\n",
      "Neuron 32: 0.0\n",
      "Neuron 33: 0.0\n",
      "Neuron 34: 0.0\n",
      "Neuron 35: 0.0\n",
      "Neuron 36: 0.0\n",
      "Neuron 37: 0.0\n",
      "Neuron 38: 0.0\n",
      "Neuron 39: 0.0\n",
      "Neuron 40: 0.0\n",
      "Neuron 41: 0.0\n",
      "Neuron 42: 0.0\n",
      "Neuron 43: 0.0\n",
      "Neuron 44: 0.0\n",
      "Neuron 45: 0.0\n",
      "Neuron 46: 0.0\n",
      "Neuron 47: 0.0\n",
      "Neuron 48: 0.0\n",
      "Neuron 49: 0.0\n",
      "Neuron 50: 0.0\n",
      "Neuron 51: 0.0\n",
      "Neuron 52: 0.0\n",
      "Neuron 53: 0.0\n",
      "Neuron 54: 0.0\n",
      "Neuron 55: 0.0\n",
      "Neuron 56: 0.0\n",
      "Neuron 57: 0.0\n",
      "Neuron 58: 0.0\n",
      "Neuron 59: 0.0\n",
      "Neuron 60: 0.0\n",
      "Neuron 61: 0.0\n",
      "Neuron 62: 0.0\n",
      "Neuron 63: 0.0\n",
      "Neuron 64: 0.0\n",
      "Neuron 65: 0.0\n",
      "Neuron 66: 0.0\n",
      "Neuron 67: 0.0\n",
      "Neuron 68: 0.0\n",
      "Neuron 69: 0.0\n",
      "Neuron 70: 0.0\n",
      "Neuron 71: 0.0\n",
      "Neuron 72: 0.0\n",
      "Neuron 73: 0.0\n",
      "Neuron 74: 0.0\n",
      "Neuron 75: 0.0\n",
      "Neuron 76: 0.0\n",
      "Neuron 77: 0.0\n",
      "Neuron 78: 0.0\n",
      "Neuron 79: 0.0\n",
      "Neuron 80: 0.0\n",
      "Neuron 81: 0.0\n",
      "Neuron 82: 0.0\n",
      "Neuron 83: 0.0\n",
      "Neuron 84: 0.0\n",
      "Neuron 85: 0.0\n",
      "Neuron 86: 0.0\n",
      "Neuron 87: 0.0\n",
      "Neuron 88: 0.0\n",
      "Neuron 89: 0.0\n",
      "Neuron 90: 0.0\n",
      "Neuron 91: 0.0\n",
      "Neuron 92: 0.0\n",
      "Neuron 93: 0.0\n",
      "Neuron 94: 0.0\n",
      "Neuron 95: 0.0\n",
      "Neuron 96: 0.0\n",
      "Neuron 97: 0.0\n",
      "Neuron 98: 0.0\n",
      "Neuron 99: 0.0\n",
      "Neuron 100: 0.0\n",
      "Neuron 101: 0.0\n",
      "Neuron 102: 0.0\n",
      "Neuron 103: 0.0\n",
      "Neuron 104: 0.0\n",
      "Neuron 105: 0.0\n",
      "Neuron 106: 0.0\n",
      "Neuron 107: 0.0\n",
      "Neuron 108: 0.0\n",
      "Neuron 109: 0.0\n",
      "Neuron 110: 0.0\n",
      "Neuron 111: 0.0\n",
      "Neuron 112: 0.0\n",
      "Neuron 113: 0.0\n",
      "Neuron 114: 0.0\n",
      "Neuron 115: 0.0\n",
      "Neuron 116: 0.0\n",
      "Neuron 117: 0.0\n",
      "Neuron 118: 0.0\n",
      "Neuron 119: 0.0\n",
      "Neuron 120: 0.0\n",
      "Neuron 121: 0.0\n",
      "Neuron 122: 0.0\n",
      "Neuron 123: 0.0\n",
      "Neuron 124: 0.0\n",
      "Neuron 125: 0.0\n",
      "Neuron 126: 0.0\n",
      "Neuron 127: 0.0\n",
      "Neuron 128: 0.0\n",
      "Neuron 129: 0.0\n",
      "Neuron 130: 0.0\n",
      "Neuron 131: 0.0\n",
      "Neuron 132: 0.0\n",
      "Neuron 133: 0.0\n",
      "Neuron 134: 0.0\n",
      "Neuron 135: 0.0\n",
      "Neuron 136: 0.0\n",
      "Neuron 137: 0.0\n",
      "Neuron 138: 0.0\n",
      "Neuron 139: 0.0\n",
      "Neuron 140: 0.0\n",
      "Neuron 141: 0.0\n",
      "Neuron 142: 0.0\n",
      "Neuron 143: 0.0\n",
      "Neuron 144: 0.0\n",
      "Neuron 145: 0.0\n",
      "Neuron 146: 0.0\n",
      "Neuron 147: 0.0\n",
      "Neuron 148: 0.0\n",
      "Neuron 149: 0.0\n",
      "Neuron 150: 0.0\n",
      "Neuron 151: 0.0\n",
      "Neuron 152: 0.0\n",
      "Neuron 153: 0.0\n",
      "Neuron 154: 0.0\n",
      "Neuron 155: 0.0\n",
      "Neuron 156: 0.0\n",
      "Neuron 157: 0.0\n",
      "Neuron 158: 0.0\n",
      "Neuron 159: 0.0\n",
      "Neuron 160: 0.0\n",
      "Neuron 161: 0.0\n",
      "Neuron 162: 0.0\n",
      "Neuron 163: 0.0\n",
      "Neuron 164: 0.0\n",
      "Neuron 165: 0.0\n",
      "Neuron 166: 0.0\n",
      "Neuron 167: 0.0\n",
      "Neuron 168: 0.0\n",
      "Neuron 169: 0.0\n",
      "Neuron 170: 0.0\n",
      "Neuron 171: 0.0\n",
      "Neuron 172: 0.0\n",
      "Neuron 173: 0.0\n",
      "Neuron 174: 0.0\n",
      "Neuron 175: 0.0\n",
      "Neuron 176: 0.0\n",
      "Neuron 177: 0.0\n",
      "Neuron 178: 0.0\n",
      "Neuron 179: 0.0\n",
      "Neuron 180: 0.0\n",
      "Neuron 181: 0.0\n",
      "Neuron 182: 0.0\n",
      "Neuron 183: 0.0\n",
      "Neuron 184: 0.0\n",
      "Neuron 185: 0.0\n",
      "Neuron 186: 0.0\n",
      "Neuron 187: 0.0\n",
      "Neuron 188: 0.0\n",
      "Neuron 189: 0.0\n",
      "Neuron 190: 0.0\n",
      "Neuron 191: 0.0\n",
      "Neuron 192: 0.0\n",
      "Neuron 193: 0.0\n",
      "Neuron 194: 0.0\n",
      "Neuron 195: 0.0\n",
      "Neuron 196: 0.0\n",
      "Neuron 197: 0.0\n",
      "Neuron 198: 0.0\n",
      "Neuron 199: 0.0\n",
      "Neuron 200: 0.0\n",
      "Neuron 201: 0.0\n",
      "Neuron 202: 0.0\n",
      "Neuron 203: 0.0\n",
      "Neuron 204: 0.0\n",
      "Neuron 205: 0.0\n",
      "Neuron 206: 0.0\n",
      "Neuron 207: 0.0\n",
      "Neuron 208: 0.0\n",
      "Neuron 209: 0.0\n",
      "Neuron 210: 0.0\n",
      "Neuron 211: 0.0\n",
      "Neuron 212: 0.0\n",
      "Neuron 213: 0.0\n",
      "Neuron 214: 0.0\n",
      "Neuron 215: 0.0\n",
      "Neuron 216: 0.0\n",
      "Neuron 217: 0.0\n",
      "Neuron 218: 0.0\n",
      "Neuron 219: 0.0\n",
      "Neuron 220: 0.0\n",
      "Neuron 221: 0.0\n",
      "Neuron 222: 0.0\n",
      "Neuron 223: 0.0\n",
      "Neuron 224: 0.0\n",
      "Neuron 225: 0.0\n",
      "Neuron 226: 0.0\n",
      "Neuron 227: 0.0\n",
      "Neuron 228: 0.0\n",
      "Neuron 229: 0.0\n",
      "Neuron 230: 0.0\n",
      "Neuron 231: 0.0\n",
      "Neuron 232: 0.0\n",
      "Neuron 233: 0.0\n",
      "Neuron 234: 0.0\n",
      "Neuron 235: 0.0\n",
      "Neuron 236: 0.0\n",
      "Neuron 237: 0.0\n",
      "Neuron 238: 0.0\n",
      "Neuron 239: 0.0\n",
      "Neuron 240: 0.0\n",
      "Neuron 241: 0.0\n",
      "Neuron 242: 0.0\n",
      "Neuron 243: 0.0\n",
      "Neuron 244: 0.0\n",
      "Neuron 245: 0.0\n",
      "Neuron 246: 0.0\n",
      "Neuron 247: 0.0\n",
      "Neuron 248: 0.0\n",
      "Neuron 249: 0.0\n",
      "Neuron 250: 0.0\n",
      "Neuron 251: 0.0\n",
      "Neuron 252: 0.0\n",
      "Neuron 253: 0.0\n",
      "Neuron 254: 0.0\n",
      "Neuron 255: 0.0\n",
      "Neuron 256: 0.0\n",
      "Neuron 257: 0.0\n",
      "Neuron 258: 0.0\n",
      "Neuron 259: 0.0\n",
      "Neuron 260: 0.0\n",
      "Neuron 261: 0.0\n",
      "Neuron 262: 0.0\n",
      "Neuron 263: 0.0\n",
      "Neuron 264: 0.0\n",
      "Neuron 265: 0.0\n",
      "Neuron 266: 0.0\n",
      "Neuron 267: 0.0\n",
      "Neuron 268: 0.0\n",
      "Neuron 269: 0.0\n",
      "Neuron 270: 0.0\n",
      "Neuron 271: 0.0\n",
      "Neuron 272: 0.0\n",
      "Neuron 273: 0.0\n",
      "Neuron 274: 0.0\n",
      "Neuron 275: 0.0\n",
      "Neuron 276: 0.0\n",
      "Neuron 277: 0.0\n",
      "Neuron 278: 0.0\n",
      "Neuron 279: 0.0\n",
      "Neuron 280: 0.0\n",
      "Neuron 281: 0.0\n",
      "Neuron 282: 0.0\n",
      "Neuron 283: 0.0\n",
      "Neuron 284: 0.0\n",
      "Neuron 285: 0.0\n",
      "Neuron 286: 0.0\n",
      "Neuron 287: 0.0\n",
      "Neuron 288: 0.0\n",
      "Neuron 289: 0.0\n",
      "Neuron 290: 0.0\n",
      "Neuron 291: 0.0\n",
      "Neuron 292: 0.0\n",
      "Neuron 293: 0.0\n",
      "Neuron 294: 0.0\n",
      "Neuron 295: 0.0\n",
      "Neuron 296: 0.0\n",
      "Neuron 297: 0.0\n",
      "Neuron 298: 0.0\n",
      "Neuron 299: 0.0\n",
      "Neuron 300: 0.0\n",
      "Neuron 301: 0.0\n",
      "Neuron 302: 0.0\n",
      "Neuron 303: 0.0\n",
      "Neuron 304: 0.0\n",
      "Neuron 305: 0.0\n",
      "Neuron 306: 0.0\n",
      "Neuron 307: 0.0\n",
      "Neuron 308: 0.0\n",
      "Neuron 309: 0.0\n",
      "Neuron 310: 0.0\n",
      "Neuron 311: 0.0\n",
      "Neuron 312: 0.0\n",
      "Neuron 313: 0.0\n",
      "Neuron 314: 0.0\n",
      "Neuron 315: 0.0\n",
      "Neuron 316: 0.0\n",
      "Neuron 317: 0.0\n",
      "Neuron 318: 0.0\n",
      "Neuron 319: 0.0\n",
      "Neuron 320: 0.0\n",
      "Neuron 321: 0.0\n",
      "Neuron 322: 0.0\n",
      "Neuron 323: 0.0\n",
      "Neuron 324: 0.0\n",
      "Neuron 325: 0.0\n",
      "Neuron 326: 0.0\n",
      "Neuron 327: 0.0\n",
      "Neuron 328: 0.0\n",
      "Neuron 329: 0.0\n",
      "Neuron 330: 0.0\n",
      "Neuron 331: 0.0\n",
      "Neuron 332: 0.0\n",
      "Neuron 333: 0.0\n",
      "Neuron 334: 0.0\n",
      "Neuron 335: 0.0\n",
      "Neuron 336: 0.0\n",
      "Neuron 337: 0.0\n",
      "Neuron 338: 0.0\n",
      "Neuron 339: 0.0\n",
      "Neuron 340: 0.0\n",
      "Neuron 341: 0.0\n",
      "Neuron 342: 0.0\n",
      "Neuron 343: 0.0\n",
      "Neuron 344: 0.0\n",
      "Neuron 345: 0.0\n",
      "Neuron 346: 0.0\n",
      "Neuron 347: 0.0\n",
      "Neuron 348: 0.0\n",
      "Neuron 349: 0.0\n",
      "Neuron 350: 0.0\n",
      "Neuron 351: 0.0\n",
      "Neuron 352: 0.0\n",
      "Neuron 353: 0.0\n",
      "Neuron 354: 0.0\n",
      "Neuron 355: 0.0\n",
      "Neuron 356: 0.0\n",
      "Neuron 357: 0.0\n",
      "Neuron 358: 0.0\n",
      "Neuron 359: 0.0\n",
      "Neuron 360: 0.0\n",
      "Neuron 361: 0.0\n",
      "Neuron 362: 0.0\n",
      "Neuron 363: 0.0\n",
      "Neuron 364: 0.0\n",
      "Neuron 366: 0.0\n",
      "Neuron 367: 0.0\n",
      "Neuron 368: 0.0\n",
      "Neuron 369: 0.0\n",
      "Neuron 370: 0.0\n",
      "Neuron 371: 0.0\n",
      "Neuron 372: 0.0\n",
      "Neuron 373: 0.0\n",
      "Neuron 374: 0.0\n",
      "Neuron 375: 0.0\n",
      "Neuron 376: 0.0\n",
      "Neuron 377: 0.0\n",
      "Neuron 378: 0.0\n",
      "Neuron 379: 0.0\n",
      "Neuron 380: 0.0\n",
      "Neuron 381: 0.0\n",
      "Neuron 382: 0.0\n",
      "Neuron 383: 0.0\n",
      "Neuron 384: 0.0\n",
      "Neuron 385: 0.0\n",
      "Neuron 386: 0.0\n",
      "Neuron 387: 0.0\n",
      "Neuron 388: 0.0\n",
      "Neuron 389: 0.0\n",
      "Neuron 390: 0.0\n",
      "Neuron 391: 0.0\n",
      "Neuron 392: 0.0\n",
      "Neuron 393: 0.0\n",
      "Neuron 394: 0.0\n",
      "Neuron 395: 0.0\n",
      "Neuron 396: 0.0\n",
      "Neuron 397: 0.0\n",
      "Neuron 398: 0.0\n",
      "Neuron 399: 0.0\n",
      "Neuron 400: 0.0\n",
      "Neuron 401: 0.0\n",
      "Neuron 402: 0.0\n",
      "Neuron 403: 0.0\n",
      "Neuron 404: 0.0\n",
      "Neuron 405: 0.0\n",
      "Neuron 406: 0.0\n",
      "Neuron 407: 0.0\n",
      "Neuron 408: 0.0\n",
      "Neuron 409: 0.0\n",
      "Neuron 410: 0.0\n",
      "Neuron 411: 0.0\n",
      "Neuron 412: 0.0\n",
      "Neuron 413: 0.0\n",
      "Neuron 414: 0.0\n",
      "Neuron 415: 0.0\n",
      "Neuron 416: 0.0\n",
      "Neuron 417: 0.0\n",
      "Neuron 418: 0.0\n",
      "Neuron 419: 0.0\n",
      "Neuron 420: 0.0\n",
      "Neuron 421: 0.0\n",
      "Neuron 422: 0.0\n",
      "Neuron 423: 0.0\n",
      "Neuron 424: 0.0\n",
      "Neuron 425: 0.0\n",
      "Neuron 426: 0.0\n",
      "Neuron 427: 0.0\n",
      "Neuron 428: 0.0\n",
      "Neuron 429: 0.0\n",
      "Neuron 430: 0.0\n",
      "Neuron 431: 0.0\n",
      "Neuron 432: 0.0\n",
      "Neuron 433: 0.0\n",
      "Neuron 434: 0.0\n",
      "Neuron 435: 0.0\n",
      "Neuron 436: 0.0\n",
      "Neuron 437: 0.0\n",
      "Neuron 438: 0.0\n",
      "Neuron 439: 0.0\n",
      "Neuron 440: 0.0\n",
      "Neuron 441: 0.0\n",
      "Neuron 442: 0.0\n",
      "Neuron 443: 0.0\n",
      "Neuron 444: 0.0\n",
      "Neuron 445: 0.0\n",
      "Neuron 446: 0.0\n",
      "Neuron 447: 0.0\n",
      "Neuron 448: 0.0\n",
      "Neuron 449: 0.0\n",
      "Neuron 450: 0.0\n",
      "Neuron 451: 0.0\n",
      "Neuron 452: 0.0\n",
      "Neuron 453: 0.0\n",
      "Neuron 454: 0.0\n",
      "Neuron 455: 0.0\n",
      "Neuron 456: 0.0\n",
      "Neuron 457: 0.0\n",
      "Neuron 458: 0.0\n",
      "Neuron 459: 0.0\n",
      "Neuron 460: 0.0\n",
      "Neuron 461: 0.0\n",
      "Neuron 462: 0.0\n",
      "Neuron 463: 0.0\n",
      "Neuron 464: 0.0\n",
      "Neuron 465: 0.0\n",
      "Neuron 466: 0.0\n",
      "Neuron 467: 0.0\n",
      "Neuron 468: 0.0\n",
      "Neuron 469: 0.0\n",
      "Neuron 470: 0.0\n",
      "Neuron 471: 0.0\n",
      "Neuron 472: 0.0\n",
      "Neuron 473: 0.0\n",
      "Neuron 474: 0.0\n",
      "Neuron 475: 0.0\n",
      "Neuron 476: 0.0\n",
      "Neuron 477: 0.0\n",
      "Neuron 478: 0.0\n",
      "Neuron 479: 0.0\n",
      "Neuron 480: 0.0\n",
      "Neuron 481: 0.0\n",
      "Neuron 482: 0.0\n",
      "Neuron 483: 0.0\n",
      "Neuron 484: 0.0\n",
      "Neuron 485: 0.0\n",
      "Neuron 486: 0.0\n",
      "Neuron 487: 0.0\n",
      "Neuron 488: 0.0\n",
      "Neuron 489: 0.0\n",
      "Neuron 490: 0.0\n",
      "Neuron 491: 0.0\n",
      "Neuron 492: 0.0\n",
      "Neuron 493: 0.0\n",
      "Neuron 494: 0.0\n",
      "Neuron 495: 0.0\n",
      "Neuron 496: 0.0\n",
      "Neuron 497: 0.0\n",
      "Neuron 498: 0.0\n",
      "Neuron 499: 0.0\n",
      "Neuron 500: 0.0\n",
      "Neuron 501: 0.0\n",
      "Neuron 502: 0.0\n",
      "Neuron 503: 0.0\n",
      "Neuron 504: 0.0\n",
      "Neuron 505: 0.0\n",
      "Neuron 506: 0.0\n",
      "Neuron 507: 0.0\n",
      "Neuron 508: 0.0\n",
      "Neuron 509: 0.0\n",
      "Neuron 510: 0.0\n",
      "Neuron 511: 0.0\n",
      "Neuron 365: 0.6053479313850403\n"
     ]
    }
   ],
   "source": [
    "# # # 用于检测权重是否被修改\n",
    "# last_conv_layer = model.layers[-12]\n",
    "# last_conv_layer_model = tf.keras.models.Model(model.inputs, last_conv_layer.output)\n",
    "# conv_outputs = last_conv_layer_model.predict(test_dataset)\n",
    "# # #用于检测权重是否被修改\n",
    "# average_activations = tf.reduce_mean(conv_outputs, axis=(0,1,2)) # 计算每个神经元在整个测试数据集上的平均激活值\n",
    "# sorted_indices = tf.argsort(average_activations, direction='ASCENDING') # 对平均激活值进行排序\n",
    "# for i in range(len(sorted_indices)): #打印排序后的神经元及其对应的平均激活值\n",
    "#     print(f\"Neuron {sorted_indices[i]}: {average_activations[sorted_indices[i]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ea0528c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(0, average_output.shape[2]), accuracies)\n",
    "plt.xlabel('Number of pruned neurons')\n",
    "plt.ylabel('Test accuracy')\n",
    "plt.title('Test accuracy change process')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd37e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
