{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2530302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_testset():\n",
    "    # 在整个测试集上评估，返回分类评估指标日志\n",
    "    \n",
    "    # 交叉熵损失函数\n",
    "    criterion = nn.CrossEntropyLoss() \n",
    "    loss_list = []\n",
    "    labels_list = []\n",
    "    preds_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader: # 生成一个 batch 的数据和标注\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images) # 输入模型，执行前向预测\n",
    "            # outputs = outputs.logits\n",
    "            # 获取整个测试集的标签类别和预测类别\n",
    "            _, preds = torch.max(outputs, 1) # 获得当前 batch 所有图像的预测类别\n",
    "            preds = preds.cpu().numpy()\n",
    "            loss = criterion(outputs, labels) # 由 logit，计算当前 batch 中，每个样本的平均交叉熵损失函数值\n",
    "            loss = loss.detach().cpu().numpy()\n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "            labels = labels.detach().cpu().numpy()\n",
    "\n",
    "            loss_list.append(loss)\n",
    "            labels_list.extend(labels)\n",
    "            preds_list.extend(preds)\n",
    "        \n",
    "    log_test = {}\n",
    "    \n",
    "    # 计算分类评估指标\n",
    "    log_test['test_loss'] = np.mean(loss)\n",
    "    log_test['test_accuracy'] = accuracy_score(labels_list, preds_list)\n",
    "    log_test['test_precision'] = precision_score(labels_list, preds_list, average='macro')\n",
    "    log_test['test_recall'] = recall_score(labels_list, preds_list, average='macro')\n",
    "    log_test['test_f1-score'] = f1_score(labels_list, preds_list, average='macro')\n",
    "    \n",
    "    return log_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "811eb2d6-2782-4c09-93e0-c0eef01f4233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 0.9983333333333333, 0.9976666666666667, 0.9903333333333333, 0.9743333333333334, 0.9853333333333333, 0.9653333333333334, 0.9626666666666667, 0.9136666666666666, 0.9273333333333333, 0.8803333333333333, 0.8196666666666667, 0.532, 0.3333333333333333]\n",
      "[7.5420765e-05, 6.981732e-05, 7.1048555e-05, 5.9685808e-05, 0.00017323195, 0.00021742497, 0.0031757485, 0.006021244, 0.0030844714, 0.0036849945, 0.0019149194, 0.022595167, 0.05196352, 0.32560533, 0.8809403, 1.2620946]\n",
      "[1.0, 1.0, 1.0, 0.9983416252072969, 0.9976828864614365, 0.9906057661159702, 0.9761683689260291, 0.9859514687100894, 0.9685990338164251, 0.9664268585131893, 0.9314270585120465, 0.9393590682428427, 0.903869815806759, 0.8320145942734257, 0.6926977309538548, 0.1111111111111111]\n",
      "[1.0, 1.0, 1.0, 0.9983333333333334, 0.9976666666666666, 0.9903333333333334, 0.9743333333333334, 0.9853333333333333, 0.9653333333333333, 0.9626666666666667, 0.9136666666666667, 0.9273333333333333, 0.8803333333333333, 0.8196666666666667, 0.5319999999999999, 0.3333333333333333]\n",
      "[1.0, 1.0, 1.0, 0.9983333229166016, 0.9976666380829832, 0.9903313004892613, 0.97429523244162, 0.9853262312292482, 0.9652393405100725, 0.9625492210237973, 0.9121941404505577, 0.9265232521887139, 0.8772893420751858, 0.8134320014715516, 0.42195295245683373, 0.16666666666666666]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_save)\n",
    "print(loss_save)\n",
    "print(precision_save)\n",
    "print(recall_save)\n",
    "print(f1_score_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cccdeb17-2a42-4a6b-8b84-b59fb31588f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "# 交叉熵损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # 将学习率设置为原来的 1/10\n",
    "\n",
    "# 训练轮次 Epoch\n",
    "EPOCHS = 5\n",
    "batch_idx = 0\n",
    "# 学习率降低策略\n",
    "lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71b929b7-72cc-4f3e-8601-fee77259b892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_batch(images, labels):\n",
    "    # 运行一个 batch 的训练，返回当前 batch 的训练日志\n",
    "    \n",
    "    # 获得一个 batch 的数据和标注\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    outputs = model(images) # 输入模型，执行前向预测\n",
    "    loss = criterion(outputs, labels) # 计算当前 batch 中，每个样本的平均交叉熵损失函数值\n",
    "    \n",
    "    # 优化更新权重\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 获取当前 batch 的标签类别和预测类别\n",
    "    _, preds = torch.max(outputs, 1) # 获得当前 batch 所有图像的预测类别\n",
    "    preds = preds.cpu().numpy()\n",
    "    loss = loss.detach().cpu().numpy()\n",
    "    outputs = outputs.detach().cpu().numpy()\n",
    "    labels = labels.detach().cpu().numpy()\n",
    "    \n",
    "    log_train = {}\n",
    "    log_train['epoch'] = epoch\n",
    "    log_train['batch'] = batch_idx\n",
    "    # 计算分类评估指标 用于动态监测loss与accuracy\n",
    "    log_train['train_loss'] = loss\n",
    "    log_train['train_accuracy'] = accuracy_score(labels, preds)\n",
    "    # log_train['train_precision'] = precision_score(labels, preds, average='macro')\n",
    "    # log_train['train_recall'] = recall_score(labels, preds, average='macro')\n",
    "    # log_train['train_f1-score'] = f1_score(labels, preds, average='macro')\n",
    "    \n",
    "    return log_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d59ca4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:38<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.0012905959, 'test_accuracy': 0.9993333333333333, 'test_precision': 0.9993346640053226, 'test_recall': 0.9993333333333334, 'test_f1-score': 0.9993333326666659}\n",
      "保存新的最佳模型 ./fine_tuned_pruned_resnet50-0.000.pth\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:38<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.0012217328, 'test_accuracy': 0.9993333333333333, 'test_precision': 0.9993346640053226, 'test_recall': 0.9993333333333334, 'test_f1-score': 0.9993333326666659}\n",
      "保存新的最佳模型 ./fine_tuned_pruned_resnet50-0.999.pth\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:38<00:00,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.0009464224, 'test_accuracy': 0.9993333333333333, 'test_precision': 0.9993346640053226, 'test_recall': 0.9993333333333334, 'test_f1-score': 0.9993333326666659}\n",
      "保存新的最佳模型 ./fine_tuned_pruned_resnet50-0.999.pth\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:38<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.0012235055, 'test_accuracy': 0.9993333333333333, 'test_precision': 0.9993346640053226, 'test_recall': 0.9993333333333334, 'test_f1-score': 0.9993333326666659}\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:37<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.0014658093, 'test_accuracy': 0.9993333333333333, 'test_precision': 0.9993346640053226, 'test_recall': 0.9993333333333334, 'test_f1-score': 0.9993333326666659}\n"
     ]
    }
   ],
   "source": [
    "# 载入剪枝后的模型作为当前模型\n",
    "model = torch.load('pruned_resnet50.pth')\n",
    "model = model.to(device)\n",
    "\n",
    "# 微调模型\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    \n",
    "    print(f'Epoch {epoch}/{EPOCHS}')  # 打印当前训练轮数\n",
    "    \n",
    "    ## 训练阶段\n",
    "    model.train()\n",
    "    for images, labels in tqdm(train_loader):  # 获得一个 batch 的数据和标注\n",
    "        batch_idx += 1\n",
    "        log_train = train_one_batch(images, labels)  # 一次训练一个batch\n",
    "        df_train_log = df_train_log.append(log_train, ignore_index=True)\n",
    "        \n",
    "    lr_scheduler.step()\n",
    "\n",
    "    ## 测试阶段\n",
    "    model.eval()\n",
    "    log_test = evaluate_testset()\n",
    "    print(log_test)\n",
    "    df_test_log = df_test_log.append(log_test, ignore_index=True)\n",
    "    \n",
    "    if log_test['test_accuracy'] >= best_test_accuracy: \n",
    "        if log_test['test_loss'] < best_test_loss: \n",
    "            # 删除旧的最佳模型文件(如有)\n",
    "            old_best_checkpoint_path = './fine_tuned_pruned_resnet50-{:.3f}.pth'.format(best_test_accuracy)\n",
    "            if os.path.exists(old_best_checkpoint_path):\n",
    "                os.remove(old_best_checkpoint_path)\n",
    "            # 保存新的最佳模型文件\n",
    "            new_best_checkpoint_path = './fine_tuned_pruned_resnet50-{:.3f}.pth'.format(log_test['test_accuracy'])\n",
    "            torch.save(model, new_best_checkpoint_path)\n",
    "            print('保存新的最佳模型', './fine_tuned_pruned_resnet50-{:.3f}.pth'.format(best_test_accuracy))\n",
    "            best_test_accuracy = log_test['test_accuracy']\n",
    "            best_test_loss = log_test['test_loss']\n",
    "\n",
    "# # 保存微调后的模型\n",
    "# torch.save(model, 'fine_tuned_pruned_resnet50-{:.3f}.pth')\n",
    "\n",
    "# # 评估微调后的模型\n",
    "# model.eval()\n",
    "# print(evaluate_testset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22ebbfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.0009464224, 'test_accuracy': 0.9993333333333333, 'test_precision': 0.9993346640053226, 'test_recall': 0.9993333333333334, 'test_f1-score': 0.9993333326666659}\n"
     ]
    }
   ],
   "source": [
    "# 评估微调后的模型\n",
    "model = torch.load('fine_tuned_pruned_resnet50-0.999.pth')\n",
    "model.eval()\n",
    "print(evaluate_testset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8fbefa-3962-4e8e-9ee7-861d92ff712c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
